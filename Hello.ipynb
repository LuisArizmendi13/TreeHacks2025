{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e5dba6-7f9d-4555-8854-3b4a7d910479",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hello World')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70d807bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (4.48.3)\n",
      "Requirement already satisfied: torch in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (2.6.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: openai in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (1.63.0)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/miniconda/envs/treehack/lib/python3.10/site-packages (from requests->transformers) (2.3.0)\n",
      "Downloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m29.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:06\u001b[0m00:18\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchvision\n",
      "Successfully installed torchvision-0.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch torchvision openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eed1556d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 1/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00001.mp4\n",
      "Question: Was ego doing a legal maneuver if its goal is to turn right at the intersection? A. It's legal as the lane is empty. B. It's illegal as the right turn lane is bloacked by construction. C. It's illegal as ego was cutting in other vehicles that were waiting. D. It's legal but the lane ahead is way too narrow for ego to pass.\n",
      "Frame 1:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, A construction barrier, An emergency vehicle, A pedestrian waiting at the crosswalk\n",
      " - Description: a car driving down a road with construction cones and traffic cones\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A parked vehicle, A car merging into a lane, A construction barrier, An emergency vehicle, A pedestrian waiting at the crosswalk\n",
      " - Description: a car driving down a road with construction cones and a traffic light\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A car merging into a lane, A construction barrier, A one way signA cyclist on the road\n",
      " - Description: a car driving down a road with construction cones\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A construction barrier, A parked vehicle, An emergency vehicle, A car merging into a lane, A broken traffic light\n",
      " - Description: a car driving down a street with construction cones and a traffic light\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A construction barrier, An emergency vehicle, A parked vehicle, A broken traffic light, A yield sign\n",
      " - Description: a view of a road with traffic and construction cones\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A construction barrier, A broken traffic light, A car merging into a lane, An emergency vehicle, A red traffic light\n",
      " - Description: a street with a lot of cars and cones\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A construction barrier, A car merging into a lane, A pedestrian waiting at the crosswalk, A red traffic light, A parked vehicle\n",
      " - Description: a street with a lot of cars and cones\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A construction barrier, A car merging into a lane, A parked vehicle, An emergency vehicle, A red traffic light\n",
      " - Description: a view of a busy street with cars and trucks\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00001.mp4\n",
      "Answer: The best answer is B. It's illegal as the right turn lane is blocked by construction. This is justified because the presence of a construction barrier indicates that the right turn lane is not accessible for legal maneuvering.\n",
      "\n",
      "Processing 2/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00002.mp4\n",
      "Question: Where can ego legally park on this street? A. No parking anywhere. B. next to right curb. C. anywhere. D. next to left curb.\n",
      "Frame 1:\n",
      " - Detected Objects: A construction barrier, A broken traffic light, A parked vehicle, A pedestrian crossing the street, An emergency vehicle\n",
      " - Description: a street with a lot of traffic and buildings\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A construction barrier, A parked vehicle, A pedestrian crossing the street, An emergency vehicle, A pedestrian waiting at the crosswalk\n",
      " - Description: a street with a lot of traffic cones and cars\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: An emergency vehicle, A pedestrian waiting at the crosswalk, A broken traffic light, A parked vehicle, A pedestrian crossing the street\n",
      " - Description: a parking lot with a few cars parked in it\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A pedestrian waiting at the crosswalk, A car merging into a lane, A pedestrian crossing the street\n",
      " - Description: a car parked in front of a restaurant at night\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A car merging into a lane, A pedestrian waiting at the crosswalk, A broken traffic light\n",
      " - Description: a small car is driving down the street at night\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A construction barrier, An emergency vehicle, A parked vehicle, A broken traffic light, A pedestrian waiting at the crosswalk\n",
      " - Description: a car driving down a dark street at night\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A construction barrier, A parked vehicle, A broken traffic light, An emergency vehicle, A pedestrian waiting at the crosswalk\n",
      " - Description: a street at night with a street light\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A construction barrier, An emergency vehicle, A broken traffic light, A parked vehicle, A pedestrian waiting at the crosswalk\n",
      " - Description: a street at night with a street light and cones\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00002.mp4\n",
      "Answer: The best answer is **A. No parking anywhere.** This conclusion is based on the presence of construction barriers and emergency vehicles consistently mentioned throughout the frames, suggesting that parking is restricted in the area.\n",
      "\n",
      "Processing 3/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00003.mp4\n",
      "Question: What is the best description of the maneuver ego just did? A. Lane change to the left and then lane change to the right. B. Lane change to the right and then lane change to the left. C. Staying in a lane which curves to the left and then to the right. D. Staying in a lane which curves to the right and then to the left.\n",
      "Frame 1:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, A one way signA cyclist on the road, An emergency vehicle, A broken traffic light\n",
      " - Description: a car driving down a street with trees on either side\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A car merging into a lane, A one way signA cyclist on the road, A parked vehicle, An emergency vehicle, A pedestrian crossing the street\n",
      " - Description: a car driving down a street with trees and houses\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A parked vehicle, A one way signA cyclist on the road, A car merging into a lane, An emergency vehicle, A pedestrian crossing the street\n",
      " - Description: a car driving down a street with a stop sign\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A parked vehicle, A car merging into a lane, An emergency vehicle, A one way signA cyclist on the road, A broken traffic light\n",
      " - Description: a car driving down a street with a stop sign\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A car merging into a lane, A one way signA cyclist on the road, A red traffic light\n",
      " - Description: a street with cars driving down it\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A one way signA cyclist on the road, A parked vehicle, An emergency vehicle, A car merging into a lane, A pedestrian crossing the street\n",
      " - Description: a street with a yellow line on it\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A broken traffic light, An emergency vehicle, A parked vehicle, A yield sign, A stop sign\n",
      " - Description: a street with a yellow line on it\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A one way signA cyclist on the road, A yield sign, A car merging into a lane\n",
      " - Description: a street with a yellow line on it\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00003.mp4\n",
      "Answer: Based on the provided frames, the best description of the maneuver ego just did is **C. Staying in a lane which curves to the left and then to the right.** This is because the descriptions consistently indicate the presence of a yellow line on the road, suggesting that ego was navigating along a curved path rather than changing lanes.\n",
      "\n",
      "Processing 4/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00004.mp4\n",
      "Question: Why is ego stopped? A. Judah. B. Traffic Light. C. Someone is crossing the road. D. Construction.\n",
      "Frame 1:\n",
      " - Detected Objects: A construction barrier, A broken traffic light, A one way signA cyclist on the road, A car merging into a lane, A red traffic light\n",
      " - Description: a street with a traffic light and a hill in the background\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A construction barrier, A car merging into a lane, A broken traffic light, A one way signA cyclist on the road, A red traffic light\n",
      " - Description: a street with a traffic light and a crosswalk\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A one way signA cyclist on the road, A construction barrier, A car merging into a lane, An emergency vehicle, A parked vehicle\n",
      " - Description: a street with a crosswalk and a traffic light\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A one way signA cyclist on the road, A construction barrier, An emergency vehicle, A parked vehicle, A pedestrian crossing the street\n",
      " - Description: a street with a crosswalk and a stop sign\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A one way signA cyclist on the road, A car merging into a lane, A construction barrier, An emergency vehicle, A parked vehicle\n",
      " - Description: a street with a crosswalk and a traffic light\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A one way signA cyclist on the road, A construction barrier, An emergency vehicle, A car merging into a lane, A parked vehicle\n",
      " - Description: a street with a stop sign and a pole\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A one way signA cyclist on the road, A construction barrier, A car merging into a lane, A parked vehicle, An emergency vehicle\n",
      " - Description: a street with a stop sign and a car on it\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A one way signA cyclist on the road, A construction barrier, A parked vehicle, A car merging into a lane, An emergency vehicle\n",
      " - Description: a street with a stop sign and a car\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00004.mp4\n",
      "Answer: C. Someone is crossing the road. \n",
      "\n",
      "Justification: The frames indicate the presence of a pedestrian crossing the street, which is a likely cause for stopping, especially in conjunction with the other road elements observed.\n",
      "\n",
      "Processing 5/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00005.mp4\n",
      "Question: What is the blinker state of the oncoming car, with respect to the oncoming car itself? A. LEFT. B. RIGHT. C. BOTH. D. OFF.\n",
      "Frame 1:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A pedestrian crossing the street, A broken traffic light, A pedestrian waiting at the crosswalk\n",
      " - Description: a car driving down a street at night\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A parked vehicle, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A broken traffic light, An emergency vehicle\n",
      " - Description: a car driving down a street at night\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A parked vehicle, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, An emergency vehicle, A broken traffic light\n",
      " - Description: a car driving down a street at night\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A parked vehicle, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, An emergency vehicle, A broken traffic light\n",
      " - Description: a street at night with cars driving down it\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A parked vehicle, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, An emergency vehicle, A broken traffic light\n",
      " - Description: a street at night with cars driving down it\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A parked vehicle, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, An emergency vehicle, A broken traffic light\n",
      " - Description: a car driving down a street at night\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A parked vehicle, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A broken traffic light, An emergency vehicle\n",
      " - Description: a street at night with cars driving down it\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A broken traffic light\n",
      " - Description: a street at night with cars driving down it\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00005.mp4\n",
      "Answer: D. OFF. \n",
      "\n",
      "Justification: The video consistently shows the state of the oncoming car but does not mention any blinker activity, suggesting that the oncoming car's blinker is off during the observed frames.\n",
      "\n",
      "Processing 6/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00006.mp4\n",
      "Question: What is the reason ego changed lanes to the left? A.  Left lane has better views. B. Current lane is exit only. C. Current lane has a lower speed limit. D. Current lane is blocked.\n",
      "Frame 1:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A construction barrier, A red traffic light\n",
      " - Description: a view of the freeway at night with cars driving on it\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A construction barrier, A red traffic light\n",
      " - Description: a car driving on the highway at night\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A car merging into a lane, A construction barrier, A parked vehicle, An emergency vehicle, A red traffic light\n",
      " - Description: a car driving on the highway at night\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A car merging into a lane, A construction barrier, An emergency vehicle, A parked vehicle, A one way signA cyclist on the road\n",
      " - Description: a view of the freeway at night with traffic lights\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A car merging into a lane, A construction barrier, An emergency vehicle, A parked vehicle, A red traffic light\n",
      " - Description: a car driving on a highway at night\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A car merging into a lane, A construction barrier, An emergency vehicle, A parked vehicle, A one way signA cyclist on the road\n",
      " - Description: a view of traffic on a highway at night\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A construction barrier, A car merging into a lane, An emergency vehicle, A parked vehicle, A one way signA cyclist on the road\n",
      " - Description: cars driving on the highway at night\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A car merging into a lane, A construction barrier, An emergency vehicle, A parked vehicle, A red traffic light\n",
      " - Description: a view of a highway at night with cars driving on it\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00006.mp4\n",
      "Answer: B. Current lane is exit only. \n",
      "\n",
      "Justification: The repeated presence of a construction barrier suggests potential obstructions in the current lane, and the mention of a one way sign might indicate limited options or the need to change lanes, aligning with the assumption that the current lane could be exit only.\n",
      "\n",
      "Processing 7/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00007.mp4\n",
      "Question: What is the correct behavior for ego and why? A. Continue straight in a nominal scenario. B. Slow down for a pedestrian. C. Veer left to avoid an obstacle. D. Veer right to avoid an obstacle.\n",
      "Frame 1:\n",
      " - Detected Objects: A yield sign, An emergency vehicle, A parked vehicle, A stop sign, A broken traffic light\n",
      " - Description: a car is driving down a dark road at night\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A parked vehicle, A yield sign, An emergency vehicle, A stop sign, A car merging into a lane\n",
      " - Description: a car is driving down a dark road at night\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A yield sign, An emergency vehicle, A parked vehicle, A stop sign, A broken traffic light\n",
      " - Description: a car is driving down a dark road at night\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A yield sign, A car merging into a lane, A stop sign\n",
      " - Description: a car is driving down a dark road at night\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A car merging into a lane, A yield sign, A stop sign\n",
      " - Description: a car driving down a dark road at night\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A car merging into a lane, A yield sign, A stop sign\n",
      " - Description: a car is parked on the side of the road at night\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A yield sign, A car merging into a lane, A stop sign\n",
      " - Description: a car is parked on the side of the road at night\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A car merging into a lane, A yield sign, A stop sign\n",
      " - Description: a car is driving down a dark road at night\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00007.mp4\n",
      "Answer: The correct behavior for ego is **B. Slow down for a pedestrian.** \n",
      "\n",
      "This answer is justified because, although the frames do not explicitly mention a pedestrian, the presence of an emergency vehicle, parked vehicles, and a potentially hazardous driving environment at night suggests caution is required, thereby indicating the need to slow down for any unexpected pedestrians that may enter the roadway.\n",
      "\n",
      "Processing 8/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00008.mp4\n",
      "Question: How many flashing traffic light bulbs are there? A. 0. B. 2. C. 4. D. 6.\n",
      "Frame 1:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, A pedestrian waiting at the crosswalk, A one way signA cyclist on the road, A pedestrian crossing the street\n",
      " - Description: a street with cars parked on both sides of the road\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, A pedestrian waiting at the crosswalk, A pedestrian crossing the street, An emergency vehicle\n",
      " - Description: a street with cars parked on both sides of the road\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A pedestrian crossing the street, A parked vehicle, A pedestrian waiting at the crosswalk, A car merging into a lane, A red traffic light\n",
      " - Description: a street with cars parked on both sides of the road\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A car merging into a lane, A pedestrian crossing the street, A parked vehicle, A pedestrian waiting at the crosswalk, A red traffic light\n",
      " - Description: a street with cars parked on both sides of the road\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, A pedestrian crossing the street, A red traffic light, A pedestrian waiting at the crosswalk\n",
      " - Description: a street with cars parked on both sides of the road\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, An emergency vehicle\n",
      " - Description: a street with cars parked on both sides of the road\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, A broken traffic light, A pedestrian waiting at the crosswalk, A red traffic light\n",
      " - Description: a street with cars parked on both sides of the road\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A construction barrier, A car merging into a lane, A parked vehicle, A broken traffic light, An emergency vehicle\n",
      " - Description: a street with cars parked on both sides of the road\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00008.mp4\n",
      "Answer: A. 0. \n",
      "\n",
      "Justification: Throughout the frames analyzed, there is mention of red and broken traffic lights, but no indication of flashing traffic light bulbs specifically, suggesting that the answer is zero.\n",
      "\n",
      "Processing 9/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00009.mp4\n",
      "Question: Which one if more accurate in terms of the distance from the back of the red car in front to the front bumper of the ego? A. 20m. B. 40m. C. 60m. D. 100m.\n",
      "Frame 1:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A construction barrier, A parked vehicle, A broken traffic light\n",
      " - Description: a car driving down a road with construction cones and a truck\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A construction barrier, A broken traffic light, A yield sign\n",
      " - Description: a car driving down a road with a motorcycle on top\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A construction barrier, A yield sign, A broken traffic light\n",
      " - Description: a car driving down a road with a motorcycle on top\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: An emergency vehicle, A car merging into a lane, A construction barrier, A parked vehicle, A broken traffic light\n",
      " - Description: a truck driving down a road with a sign on it\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: An emergency vehicle, A car merging into a lane, A construction barrier, A parked vehicle, A broken traffic light\n",
      " - Description: a truck driving down a road with a construction sign on it\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: An emergency vehicle, A car merging into a lane, A construction barrier, A parked vehicle, A broken traffic light\n",
      " - Description: a view of a busy road with cars and trucks\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A construction barrier, A parked vehicle, A broken traffic light\n",
      " - Description: a view of a road with a truck on it\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: An emergency vehicle, A car merging into a lane, A construction barrier, A parked vehicle, A one way signA cyclist on the road\n",
      " - Description: a view of a busy highway with cars and trucks\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00009.mp4\n",
      "Answer: The best answer is C. 60m. This is the most plausible distance that would allow a sufficient gap between the back of a red car and the front bumper of the ego vehicle, given the context of the road setting described across multiple frames.\n",
      "\n",
      "Processing 10/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00010.mp4\n",
      "Question: Ignoring pedestrian lights, how many traffic lights are relevant to ego? A. 2. B. 4. C. 6. D. 8.\n",
      "Frame 1:\n",
      " - Detected Objects: A red traffic light, A broken traffic light, A pedestrian waiting at the crosswalk, A pedestrian crossing the street, A green traffic light\n",
      " - Description: a wet street at night with red lights\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A pedestrian waiting at the crosswalk, A pedestrian crossing the street, A green traffic light\n",
      " - Description: a wet street at night\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A green traffic light\n",
      " - Description: a wet street at night\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A green traffic light\n",
      " - Description: a wet street at night\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A green traffic light\n",
      " - Description: a wet street at night\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A pedestrian waiting at the crosswalk, A pedestrian crossing the street, A green traffic light\n",
      " - Description: a wet street at night\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A pedestrian waiting at the crosswalk, A pedestrian crossing the street, A green traffic light\n",
      " - Description: a wet street at night\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A pedestrian waiting at the crosswalk, A pedestrian crossing the street, A car merging into a lane\n",
      " - Description: a wet street at night\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00010.mp4\n",
      "Answer: The best answer is **B. 4** because there are consistently two relevant traffic lights (one red and one green) detected in each frame, which totals four when considering the frames together.\n",
      "\n",
      "Processing 11/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00011.mp4\n",
      "Question: What is the status of the traffic light? A. Solid green. B. Blinking green. C. Solid red. D. Blinking red.\n",
      "Frame 1:\n",
      " - Detected Objects: An emergency vehicle, A car merging into a lane, A parked vehicle, A broken traffic light, A green traffic light\n",
      " - Description: a car driving down the street at night\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: An emergency vehicle, A car merging into a lane, A broken traffic light, A parked vehicle, A red traffic light\n",
      " - Description: a car driving down the street at night\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: An emergency vehicle, A car merging into a lane, A parked vehicle, A broken traffic light, A red traffic light\n",
      " - Description: a car is driving down a street at night\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A car merging into a lane, A broken traffic light, A parked vehicle, An emergency vehicle, A red traffic light\n",
      " - Description: a car driving down a street at night\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: An emergency vehicle, A broken traffic light, A green traffic light, A red traffic light, A car merging into a lane\n",
      " - Description: a car driving down a street at night\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: An emergency vehicle, A broken traffic light, A parked vehicle, A car merging into a lane, A red traffic light\n",
      " - Description: a car driving down a street at night\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A green traffic light, A car merging into a lane, An emergency vehicle\n",
      " - Description: a car driving down a street at night\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A green traffic light, An emergency vehicle, A pedestrian crossing the street\n",
      " - Description: a street at night with cars driving on it\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00011.mp4\n",
      "Answer: The best answer is C. Solid red.\n",
      "\n",
      "Justification: Throughout the majority of the frames (Frames 2, 3, 4, 6), the traffic light consistently shows as red, indicating that it is in a solid red state for traffic control.\n",
      "\n",
      "Processing 12/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00012.mp4\n",
      "Question: What are the available maneuvers through the intersection for the right most lane? A. Go straight only. B. Turn right only. C. Go straight and turn right. D. None of the above.\n",
      "Frame 1:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A broken traffic light, A green traffic light\n",
      " - Description: a car driving down a street with a large sign\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A car merging into a lane, A green traffic light, A construction barrier\n",
      " - Description: a car driving down a street with a traffic light\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: An emergency vehicle, A car merging into a lane, A parked vehicle, A green traffic light, A broken traffic light\n",
      " - Description: a car driving down a street with a traffic light\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A broken traffic light, A green traffic light\n",
      " - Description: a car driving down a street with a traffic light\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: An emergency vehicle, A car merging into a lane, A parked vehicle, A green traffic light, A broken traffic light\n",
      " - Description: a car driving down a street with a traffic light\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A broken traffic light, A one way signA cyclist on the road\n",
      " - Description: a car driving down a street with traffic lights\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: An emergency vehicle, A car merging into a lane, A parked vehicle, A broken traffic light, A green traffic light\n",
      " - Description: a car driving down a street with traffic lights\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A construction barrier, A one way signA cyclist on the road\n",
      " - Description: a car driving down a street with traffic lights\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00012.mp4\n",
      "Answer: C. Go straight and turn right. \n",
      "\n",
      "Justification: The presence of a green traffic light indicates that vehicles in the rightmost lane are allowed to either go straight or turn right through the intersection.\n",
      "\n",
      "Processing 13/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00013.mp4\n",
      "Question: Where is the pedestrian with respect to ego? A. On the crosswalk closest to ego. B. On the crosswalk on the left. C. On the crosswalk on the right. D. On the crosswalk at the opposite side of the intersection.\n",
      "Frame 1:\n",
      " - Detected Objects: A broken traffic light, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A red traffic light, A green traffic light\n",
      " - Description: a street with a stop light and a gas station\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A broken traffic light, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A red traffic light, A green traffic light\n",
      " - Description: a street with a stop light and a gas station\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A broken traffic light, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A red traffic light, A green traffic light\n",
      " - Description: a street at night with a gas station and a traffic light\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A broken traffic light, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A green traffic light, A red traffic light\n",
      " - Description: a street with a stop light and a gas station\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A broken traffic light, A pedestrian crossing the street, A green traffic light, A red traffic light, A pedestrian waiting at the crosswalk\n",
      " - Description: a street with a stop light and a gas station\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A broken traffic light, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A red traffic light, A green traffic light\n",
      " - Description: a street with a gas station and a stop light\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A broken traffic light, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A red traffic light, A green traffic light\n",
      " - Description: a street with a stop light and a gas station\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A broken traffic light, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A red traffic light, A green traffic light\n",
      " - Description: a street with a stop light and a gas station\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00013.mp4\n",
      "Answer: The best answer is **A. On the crosswalk closest to ego.** \n",
      "\n",
      "Justification: The repeated mention of a pedestrian crossing the street in all frames indicates that the pedestrian is actively crossing near the ego vehicle's location.\n",
      "\n",
      "Processing 14/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00014.mp4\n",
      "Question: Why does the truck ahead of ego have its blinkers on? A. To signal a lane change away from ego. B. To signal a merge towards ego. C. To show hazardous conditions. D. Its blinkers are not on.\n",
      "Frame 1:\n",
      " - Detected Objects: A car merging into a lane, A one way signA cyclist on the road, An emergency vehicle, A construction barrier, A red traffic light\n",
      " - Description: a car driving down a highway with traffic on the side\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A construction barrier, A one way signA cyclist on the road\n",
      " - Description: a view of a freeway with cars driving on it\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A red traffic light, A broken traffic light, A construction barrier\n",
      " - Description: a view of a freeway with cars driving on it\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A car merging into a lane, A one way signA cyclist on the road, An emergency vehicle, A parked vehicle, A construction barrier\n",
      " - Description: a view of a freeway with cars and trucks on it\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A one way signA cyclist on the road, A parked vehicle, A broken traffic light\n",
      " - Description: a car driving down a highway with a few cars behind it\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A construction barrier, A one way signA cyclist on the road\n",
      " - Description: a view of a freeway with cars driving on it\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A red traffic light, A broken traffic light\n",
      " - Description: a highway with cars and trucks driving on it\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A construction barrier, A parked vehicle, A red traffic light\n",
      " - Description: a car driving down a highway with a sign that says \"no left turn\"\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00014.mp4\n",
      "Answer: The best answer is **A. To signal a lane change away from ego.** This is inferred from the repeated detection of a car merging into a lane in multiple frames, indicating that the truck ahead of ego is likely signaling its intention to change lanes away from the position of the ego vehicle.\n",
      "\n",
      "Processing 15/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00015.mp4\n",
      "Question: What should ego do? A. turn right. B. pullover and yield for the emergency vehicle. C. turn left. D. come to a stop and then proceed from stop sign.\n",
      "Frame 1:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, An emergency vehicle, A pedestrian crossing the street, A red traffic light\n",
      " - Description: a street with cars parked on both sides of the road\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A car merging into a lane, A red traffic light, A pedestrian crossing the street\n",
      " - Description: a street with cars parked on both sides of the road\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, An emergency vehicle, A red traffic light, A pedestrian crossing the street\n",
      " - Description: a street with cars and a stop sign\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A pedestrian crossing the street, A yield sign, A red traffic light\n",
      " - Description: a street with cars driving down it\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A stop sign, A yield sign, A parked vehicle, A pedestrian crossing the street, An emergency vehicle\n",
      " - Description: a street with a stop sign and cars driving down it\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A stop sign, A parked vehicle, A yield sign, An emergency vehicle, A pedestrian crossing the street\n",
      " - Description: a street with a stop sign painted on it\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A car merging into a lane, A pedestrian crossing the street, A red traffic light\n",
      " - Description: a street with cars parked on both sides of the street\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A car merging into a lane, A pedestrian crossing the street, A red traffic light\n",
      " - Description: a street with cars parked on both sides\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00015.mp4\n",
      "Answer: The best answer is **B. pullover and yield for the emergency vehicle.** Justification: The repeated presence of an emergency vehicle in the frames indicates that it requires priority, necessitating ego to pull over and yield to ensure the vehicle can proceed unimpeded.\n",
      "\n",
      "Processing 16/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00016.mp4\n",
      "Question: What would be the most appropriate maneuver for ego from this position? A. Reverse. B. Turn left. C. Turn right. D. Go straight.\n",
      "Frame 1:\n",
      " - Detected Objects: A parked vehicle, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A car merging into a lane, A yield sign\n",
      " - Description: a street with houses on both sides and trees\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A parked vehicle, A pedestrian crossing the street, An emergency vehicle, A pedestrian waiting at the crosswalk, A yield sign\n",
      " - Description: a street with houses on both sides and trees on the side\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A parked vehicle, A pedestrian waiting at the crosswalk, A pedestrian crossing the street, A yield sign, A stop sign\n",
      " - Description: a street with houses on both sides and trees on either side\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A parked vehicle, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A stop sign, An emergency vehicle\n",
      " - Description: a street with trees and bushes on both sides\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A pedestrian crossing the street, A parked vehicle, A pedestrian waiting at the crosswalk, A one way signA cyclist on the road, A broken traffic light\n",
      " - Description: a street with houses on both sides and a tree in the middle\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A parked vehicle, A one way signA cyclist on the road, A yield sign\n",
      " - Description: a street with houses on both sides\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A parked vehicle, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A one way signA cyclist on the road, A yield sign\n",
      " - Description: a street with houses on both sides\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A parked vehicle, A pedestrian crossing the street, A one way signA cyclist on the road, An emergency vehicle, A pedestrian waiting at the crosswalk\n",
      " - Description: a street view of a residential area with houses and trees\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00016.mp4\n",
      "Answer: C. Turn right. \n",
      "\n",
      "Justification: Given the presence of pedestrians crossing the street and the one-way sign, turning right would be a safer maneuver to navigate the situation while respecting traffic rules.\n",
      "\n",
      "Processing 17/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00017.mp4\n",
      "Question: What hazard is on the ground? A. Mud. B. Leaves. C. Oil. D. Snow.\n",
      "Frame 1:\n",
      " - Detected Objects: A pedestrian waiting at the crosswalk, A car merging into a lane, A pedestrian crossing the street, A parked vehicle, An emergency vehicle\n",
      " - Description: a view of a street with a car driving down it\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A parked vehicle, A pedestrian waiting at the crosswalk, An emergency vehicle, A pedestrian crossing the street, A construction barrier\n",
      " - Description: a street with a car driving down it\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, An emergency vehicle, A pedestrian waiting at the crosswalk, A broken traffic light\n",
      " - Description: a car driving down a street with a building in the background\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, A pedestrian waiting at the crosswalk, An emergency vehicle, A pedestrian crossing the street\n",
      " - Description: a car is driving down a street with a building in the background\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A pedestrian waiting at the crosswalk, A pedestrian crossing the street, A parked vehicle, A car merging into a lane, A construction barrier\n",
      " - Description: a car driving down a street with a crosswalk\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A pedestrian waiting at the crosswalk, A pedestrian crossing the street, A construction barrier, A parked vehicle, An emergency vehicle\n",
      " - Description: a street with a car driving down it\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A pedestrian waiting at the crosswalk, A pedestrian crossing the street, A construction barrier, A parked vehicle, An emergency vehicle\n",
      " - Description: a street with a stop sign and a car driving down it\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A pedestrian waiting at the crosswalk, A pedestrian crossing the street, A construction barrier, An emergency vehicle, A parked vehicle\n",
      " - Description: a street with a yellow line on it\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00017.mp4\n",
      "Answer: Based on the analysis of the frames, the best answer is A. Mud. \n",
      "\n",
      "Justification: While the frames describe a street scene with various objects, the repeated mention of construction barriers suggests potential roadway hazards like mud, which is commonly present in construction zones, rather than leaves, oil, or snow.\n",
      "\n",
      "Processing 18/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00018.mp4\n",
      "Question: Why is it necessary for the car to slow down? A. For another vehicle. B. For a pedestrian. C. For an animal. D. For a traffic light.\n",
      "Frame 1:\n",
      " - Detected Objects: A car merging into a lane, A pedestrian waiting at the crosswalk, A pedestrian crossing the street, A parked vehicle, A broken traffic light\n",
      " - Description: a view of a street with cars and traffic lights\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A pedestrian waiting at the crosswalk, A broken traffic light, A pedestrian crossing the street, A car merging into a lane, A red traffic light\n",
      " - Description: a view of a street intersection with cars and a traffic light\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A pedestrian waiting at the crosswalk, An emergency vehicle, A parked vehicle\n",
      " - Description: a traffic light is on the corner of a street\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: An emergency vehicle, A pedestrian waiting at the crosswalk, A parked vehicle, A broken traffic light, A car merging into a lane\n",
      " - Description: a car is driving down the road\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A car merging into a lane, A construction barrier, A pedestrian waiting at the crosswalk\n",
      " - Description: a car is driving down a street with a traffic light\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A construction barrier, A car merging into a lane, A pedestrian waiting at the crosswalk\n",
      " - Description: a car is driving down the road\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A car merging into a lane, A pedestrian waiting at the crosswalk, A construction barrier\n",
      " - Description: a car is driving down the road\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A parked vehicle, A car merging into a lane, An emergency vehicle, A pedestrian waiting at the crosswalk, A pedestrian crossing the street\n",
      " - Description: a car driving down the street\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00018.mp4\n",
      "Answer: The best answer is **B. For a pedestrian.** The frames consistently indicate the presence of pedestrians waiting at the crosswalk and crossing the street, suggesting that it is crucial for the car to slow down to ensure their safety.\n",
      "\n",
      "Processing 19/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00019.mp4\n",
      "Question: How many lanes are there in total and which lane is best for going to Half Moon Bay? A. 4 and the right most lane. B. 5 and the right most lane. C. 4 and the second right most lane. D. 5 and the second most lane.\n",
      "Frame 1:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A construction barrier, A one way signA cyclist on the road\n",
      " - Description: a freeway with cars driving on it\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A construction barrier, A parked vehicle, A red traffic light\n",
      " - Description: a freeway with cars driving on it\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A construction barrier, A red traffic light\n",
      " - Description: a freeway with cars driving on it\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A construction barrier, A one way signA cyclist on the road\n",
      " - Description: a freeway with cars driving on it\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A construction barrier, A one way signA cyclist on the road\n",
      " - Description: a freeway with cars driving on it and a sign\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A construction barrier, A red traffic light\n",
      " - Description: a freeway with cars driving on it\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A construction barrier, A one way signA cyclist on the road\n",
      " - Description: a freeway with cars driving on it and signs\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A one way signA cyclist on the road, A construction barrier\n",
      " - Description: a freeway with cars driving on it\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00019.mp4\n",
      "Answer: Based on the provided frames, the best answer is **C. 4 and the second right most lane**. This conclusion is reached because the consistent descriptions of the frames suggest a standard freeway setup with multiple lanes, indicating that there are 4 lanes total. When considering the best route to Half Moon Bay, the second rightmost lane is typically preferred for accessing exits leading to such destinations, rather than the rightmost lane, which is often a lane for continuing on the freeway.\n",
      "\n",
      "Processing 20/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00020.mp4\n",
      "Question: Is it safe for ego to park right here? A. yes there is a parking lot here. B. Yes the shoulder is large enough. C. No there's no safe place to pullover. D. No there's a fire station.\n",
      "Frame 1:\n",
      " - Detected Objects: A one way signA cyclist on the road, A car merging into a lane, An emergency vehicle, A construction barrier, A parked vehicle\n",
      " - Description: a hillside with a sign on it\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A one way signA cyclist on the road, An emergency vehicle, A construction barrier, A car merging into a lane, A parked vehicle\n",
      " - Description: a car driving down a road with a hill in the background\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A car merging into a lane, A one way signA cyclist on the road, An emergency vehicle, A construction barrier, A yield sign\n",
      " - Description: a view of a road with a stop sign and a hill\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: An emergency vehicle, A construction barrier, A car merging into a lane, A one way signA cyclist on the road, A yield sign\n",
      " - Description: a view of a road with a stop sign and a cloud covered sky\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A car merging into a lane, A one way signA cyclist on the road, An emergency vehicle, A yield sign, A broken traffic light\n",
      " - Description: a view of a road with a car driving on it\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A yield sign, A construction barrier, A one way signA cyclist on the road\n",
      " - Description: a view of a road with a sky and trees\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A car merging into a lane, A construction barrier, An emergency vehicle, A one way signA cyclist on the road, A yield sign\n",
      " - Description: a view of a road from a car window\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A car merging into a lane, A construction barrier, An emergency vehicle, A one way signA cyclist on the road, A yield sign\n",
      " - Description: a view of a road with a yellow line\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00020.mp4\n",
      "Answer: C. No there's no safe place to pullover.\n",
      "\n",
      "Justification: Throughout the frames, multiple references to emergency vehicles, construction barriers, and the presence of a cyclist indicate that the area is not conducive to safe parking.\n",
      "\n",
      "Processing 21/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00021.mp4\n",
      "Question: What type of lane is to the right of ego? A. Bus lane. B. Bike lane. C. Carpool lane. D. Right-turn-only lane.\n",
      "Frame 1:\n",
      " - Detected Objects: An emergency vehicle, A car merging into a lane, A yield sign, A broken traffic light, A stop sign\n",
      " - Description: a street with a yellow line and a stop sign\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A broken traffic light, A one way signA cyclist on the road\n",
      " - Description: a street with a stop sign and a yellow line\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A broken traffic light, A one way signA cyclist on the road, A yield sign\n",
      " - Description: a street with a yellow line on it\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A broken traffic light, A red traffic light, A pedestrian crossing the street\n",
      " - Description: a street with a yellow line on it\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A pedestrian crossing the street, A one way signA cyclist on the road, A pedestrian waiting at the crosswalk\n",
      " - Description: a street with a yellow line on it\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A car merging into a lane, A broken traffic light, An emergency vehicle, A red traffic light, A yield sign\n",
      " - Description: a street with a yellow line and a stop sign\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A car merging into a lane, A broken traffic light, An emergency vehicle, A yield sign, A one way signA cyclist on the road\n",
      " - Description: a street with a yellow traffic light and a house\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A broken traffic light, A pedestrian waiting at the crosswalk, A one way signA cyclist on the road\n",
      " - Description: a street with a truck driving down the middle of it\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00021.mp4\n",
      "Answer: The best answer is B. Bike lane, as the analysis consistently identifies a cyclist on the road, indicating the presence of a dedicated lane for bicycles to the right of the ego vehicle.\n",
      "\n",
      "Processing 22/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00022.mp4\n",
      "Question: At what time can ego park at the side of the road? A. 9am. B. 2pm. C. 8pm. D. None of the above.\n",
      "Frame 1:\n",
      " - Detected Objects: An emergency vehicle, A red traffic light, A pedestrian crossing the street, A parked vehicle, A one way signA cyclist on the road\n",
      " - Description: a motorcycle is parked on the side of the road\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A red traffic light, An emergency vehicle, A pedestrian crossing the street, A parked vehicle, A broken traffic light\n",
      " - Description: a street with a motorcycle on it at night\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A red traffic light, A pedestrian crossing the street, A parked vehicle, An emergency vehicle, A one way signA cyclist on the road\n",
      " - Description: a motorcycle is driving down a street at night\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A one way signA cyclist on the road, A pedestrian crossing the street, A broken traffic light\n",
      " - Description: a car driving down a street at night\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A car merging into a lane, A pedestrian crossing the street, A one way signA cyclist on the road\n",
      " - Description: a car driving down a street at night\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A pedestrian crossing the street, A car merging into a lane, A broken traffic light\n",
      " - Description: a car is driving down a street at night\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A red traffic light\n",
      " - Description: a car is parked on the side of a street\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A red traffic light, A pedestrian crossing the street, A broken traffic light\n",
      " - Description: a car is parked at a stop sign on a city street\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00022.mp4\n",
      "Answer: D. None of the above.\n",
      "\n",
      "Justification: The frames indicate that the parking occurrences happen both during the night and in the presence of red traffic lights, suggesting that parking might not be permitted at those times, thus disqualifying the listed times.\n",
      "\n",
      "Processing 23/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00023.mp4\n",
      "Question: What's the state of ego-relevant traffic light? A. Green left arrow. B. Green right arrow. C. Yellow left arrow. D. Yellow right arrow.\n",
      "Frame 1:\n",
      " - Detected Objects: A construction barrier, A parked vehicle, A car merging into a lane, An emergency vehicle, A pedestrian waiting at the crosswalk\n",
      " - Description: a street with cars parked on it and a hill in the background\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, A construction barrier, An emergency vehicle, A broken traffic light\n",
      " - Description: a street with cars and a hill in the background\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A construction barrier, A car merging into a lane, A parked vehicle, An emergency vehicle, A broken traffic light\n",
      " - Description: a street with cars and a hill in the background\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A car merging into a lane, A construction barrier, A parked vehicle, An emergency vehicle, A broken traffic light\n",
      " - Description: a street with cars on it\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A construction barrier, A car merging into a lane, A parked vehicle, A pedestrian waiting at the crosswalk, A broken traffic light\n",
      " - Description: a street with cars on it and a hill in the background\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A construction barrier, A parked vehicle, A car merging into a lane, A broken traffic light, An emergency vehicle\n",
      " - Description: a street with cars and a hill in the background\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A construction barrier, A car merging into a lane, A parked vehicle, A broken traffic light, An emergency vehicle\n",
      " - Description: a street with cars on it\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A construction barrier, A car merging into a lane, A parked vehicle, A pedestrian waiting at the crosswalk, A broken traffic light\n",
      " - Description: a street with cars and a hill in the background\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00023.mp4\n",
      "Answer: Based on the analysis of the frames, the best answer is **D. Yellow right arrow**. The presence of a \"broken traffic light\" indicates that the traffic signal is not functioning properly, which usually suggests that the light would be yellow or flashing to warn drivers rather than a clear green or red signal.\n",
      "\n",
      "Processing 24/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00024.mp4\n",
      "Question: Which traffic light is the most immediately relevant for ego? A. Red light. B. Red light for right turn. C. Yellow light. D. Green light.\n",
      "Frame 1:\n",
      " - Detected Objects: A one way signA cyclist on the road, A car merging into a lane, A broken traffic light, An emergency vehicle, A pedestrian waiting at the crosswalk\n",
      " - Description: a car driving down a street at night\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A car merging into a lane, A broken traffic light, A green traffic light, A red traffic light, An emergency vehicle\n",
      " - Description: a car driving down a road at night\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A broken traffic light, A car merging into a lane, A red traffic light, A one way signA cyclist on the road, A green traffic light\n",
      " - Description: a car driving down a road at night\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A broken traffic light, A car merging into a lane, A red traffic light, A green traffic light, An emergency vehicle\n",
      " - Description: a street with a car driving on it at night\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A car merging into a lane, A broken traffic light, A red traffic light, A green traffic light, An emergency vehicle\n",
      " - Description: a car driving down a street at night\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A broken traffic light, A car merging into a lane, A red traffic light, A green traffic light, An emergency vehicle\n",
      " - Description: a car driving down a street at night\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A car merging into a lane, A green traffic light, An emergency vehicle\n",
      " - Description: a car driving down a street at night\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A broken traffic light, A car merging into a lane, A red traffic light, An emergency vehicle, A green traffic light\n",
      " - Description: a car driving down an empty street at night\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00024.mp4\n",
      "Answer: The best answer is **A. Red light** because it indicates that the ego vehicle must stop, and it is the most critical to obey for immediate safety, particularly when navigating traffic and pedestrians.\n",
      "\n",
      "Processing 25/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00025.mp4\n",
      "Question: How many vehicles appeared in the video, just consider those on the same side of ego? A. 3. B. 4. C. 5. D. 6.\n",
      "Frame 1:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A one way signA cyclist on the road, A yield sign\n",
      " - Description: a truck is driving down the road with a car behind it\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A one way signA cyclist on the road, A construction barrier\n",
      " - Description: a truck is driving down the road next to a car\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A one way signA cyclist on the road, A construction barrier\n",
      " - Description: a truck is driving down the road\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A one way signA cyclist on the road, A construction barrier\n",
      " - Description: a truck is driving down the road with a trailer behind it\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, An emergency vehicle, A one way signA cyclist on the road, A pedestrian waiting at the crosswalk\n",
      " - Description: a truck and a car driving down a highway\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A one way signA cyclist on the road, A pedestrian waiting at the crosswalk\n",
      " - Description: a truck is driving down the road with a car behind it\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, A one way signA cyclist on the road, An emergency vehicle, A yield sign\n",
      " - Description: a truck and a car driving down a road\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A one way signA cyclist on the road, A pedestrian waiting at the crosswalk\n",
      " - Description: a truck driving down the road with a white truck behind it\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00025.mp4\n",
      "Answer: The best answer is B. 4. This count includes 1 truck and 3 cars, which are consistently noted as driving in the same direction throughout the frames provided.\n",
      "\n",
      "Processing 26/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00026.mp4\n",
      "Question: Which directions can ego proceed in? A. straight. B. straight or right. C. left only. D. None of the above.\n",
      "Frame 1:\n",
      " - Detected Objects: A construction barrier, A one way signA cyclist on the road, A car merging into a lane, A broken traffic light, A red traffic light\n",
      " - Description: a street with orange and white traffic cones at night\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A construction barrier, A one way signA cyclist on the road, A car merging into a lane, An emergency vehicle, A broken traffic light\n",
      " - Description: a street with orange cones on the side of the road\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A construction barrier, An emergency vehicle, A broken traffic light, A car merging into a lane, A one way signA cyclist on the road\n",
      " - Description: a street with orange cones on the side of the road\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A construction barrier, A broken traffic light, An emergency vehicle, A yield sign, A red traffic light\n",
      " - Description: a street with orange cones and a road at night\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A construction barrier, A broken traffic light, A car merging into a lane, A one way signA cyclist on the road, An emergency vehicle\n",
      " - Description: a dark road with orange and white traffic cones\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A construction barrier, A car merging into a lane, A yield sign, A broken traffic light, An emergency vehicle\n",
      " - Description: a view of a road at night with orange cones\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A construction barrier, A yield sign, A broken traffic light, A car merging into a lane, An emergency vehicle\n",
      " - Description: a street with orange cones and traffic cones at night\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A construction barrier, A car merging into a lane, A one way signA cyclist on the road, A broken traffic light, A yield sign\n",
      " - Description: a street with orange and white traffic cones\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00026.mp4\n",
      "Answer: B. straight or right. \n",
      "\n",
      "Justification: The presence of a one-way sign suggests that ego can only proceed straight or to the right, as left turns would not be permitted in a one-way street scenario.\n",
      "\n",
      "Processing 27/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00027.mp4\n",
      "Question: What's the upcoming exit number? A. 1. B. 500. C. 27. D. 80.\n",
      "Frame 1:\n",
      " - Detected Objects: An emergency vehicle, A car merging into a lane, A parked vehicle, A construction barrier, A broken traffic light\n",
      " - Description: a car driving on a highway at night with rain\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A car merging into a lane, A broken traffic light, A yield sign, An emergency vehicle, A red traffic light\n",
      " - Description: a wet road at night with traffic on it\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, A broken traffic light, An emergency vehicle, A red traffic light\n",
      " - Description: a car driving on a wet highway at night\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, A construction barrier, An emergency vehicle, A red traffic light\n",
      " - Description: a car driving on a highway at night\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A parked vehicle, A car merging into a lane, An emergency vehicle, A construction barrier, A broken traffic light\n",
      " - Description: a car driving on a highway at night\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A construction barrier, A broken traffic light, A parked vehicle, A red traffic light, An emergency vehicle\n",
      " - Description: a car driving on a highway at night\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: An emergency vehicle, A broken traffic light, A car merging into a lane, A red traffic light, A construction barrier\n",
      " - Description: a car driving on a highway at night with green lights\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A car merging into a lane, A broken traffic light, A red traffic light\n",
      " - Description: a rainy night on the highway with traffic lights\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00027.mp4\n",
      "Answer: The best answer is C. 27.\n",
      "\n",
      "Justification: The consistent mention of merging cars, emergency vehicles, and traffic lights suggests an impending exit which has no significant indicators for very high numbers like \"500\" or \"80,\" making \"27\" a more plausible upcoming exit based on highway exit patterns and density in such driving conditions.\n",
      "\n",
      "Processing 28/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00028.mp4\n",
      "Question: Is there a vehicle to ego's left? A. Yes. B. No. C. Insufficient evidence. D. None of the above.\n",
      "Frame 1:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A pedestrian waiting at the crosswalk, A broken traffic light, A pedestrian crossing the street\n",
      " - Description: a street with a traffic light and a bridge\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: An emergency vehicle, A broken traffic light, A car merging into a lane, A red traffic light, A parked vehicle\n",
      " - Description: a street with a traffic light and a bridge\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: An emergency vehicle, A car merging into a lane, A parked vehicle, A broken traffic light, A red traffic light\n",
      " - Description: a street with a traffic light and a bridge\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A broken traffic light, An emergency vehicle, A car merging into a lane, A parked vehicle, A red traffic light\n",
      " - Description: a street with a lot of cars on it\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, An emergency vehicle, A broken traffic light, A one way signA cyclist on the road\n",
      " - Description: a car driving down a street at night\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A car merging into a lane, A broken traffic light, A one way signA cyclist on the road\n",
      " - Description: a car driving down a street at night\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: An emergency vehicle, A broken traffic light, A car merging into a lane, A parked vehicle, A red traffic light\n",
      " - Description: a dark sky with clouds\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, An emergency vehicle, A parked vehicle, A car merging into a lane\n",
      " - Description: a street with a car driving down it\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00028.mp4\n",
      "Answer: C. Insufficient evidence. \n",
      "\n",
      "Justification: The frames describe various detected objects but do not specify if the vehicles are positioned to the left of ego, nor provide clear spatial relationships to confirm their locations relative to ego.\n",
      "\n",
      "Processing 29/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00029.mp4\n",
      "Question: Why did ego come to a stop? A. Crossing vehicle. B. No space without blocking intersection. C. Stop sign. D. Cross pedestrians.\n",
      "Frame 1:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A pedestrian waiting at the crosswalk, A car merging into a lane, A pedestrian crossing the street\n",
      " - Description: a street with cars driving down it\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: An emergency vehicle, A car merging into a lane, A parked vehicle, A pedestrian waiting at the crosswalk, A pedestrian crossing the street\n",
      " - Description: a car driving down a street with a stop sign\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: An emergency vehicle, A car merging into a lane, A parked vehicle, A broken traffic light, A red traffic light\n",
      " - Description: a street with cars driving down it and a traffic light\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: An emergency vehicle, A car merging into a lane, A parked vehicle, A broken traffic light, A red traffic light\n",
      " - Description: a street with cars and a traffic light\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A car merging into a lane, A red traffic light, A construction barrier\n",
      " - Description: a street with cars driving down it and a traffic light\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A car merging into a lane, A pedestrian waiting at the crosswalk, A red traffic light\n",
      " - Description: a street with cars driving down it\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: An emergency vehicle, A pedestrian waiting at the crosswalk, A parked vehicle, A car merging into a lane, A pedestrian crossing the street\n",
      " - Description: a street with cars driving down it\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A car merging into a lane, A pedestrian waiting at the crosswalk, A red traffic light\n",
      " - Description: a street with cars driving down it\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00029.mp4\n",
      "Answer: The best answer is B. No space without blocking intersection. Justification: Throughout the frames, no stop sign or crossing pedestrians are mentioned explicitly, and the ongoing situation with merging lanes and vehicles would likely create a lack of available space for the ego vehicle to continue without potentially blocking the intersection.\n",
      "\n",
      "Processing 30/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00030.mp4\n",
      "Question: What is the most likely course of action for the vehicle in front of ego? A. Turn left. B. Go straight. C. Turn right. D. Reverse.\n",
      "Frame 1:\n",
      " - Detected Objects: An emergency vehicle, A red traffic light, A parked vehicle, A broken traffic light, A car merging into a lane\n",
      " - Description: a view of a busy street with traffic lights and cars\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: An emergency vehicle, A red traffic light, A broken traffic light, A parked vehicle, A car merging into a lane\n",
      " - Description: a view of a busy street with cars and trucks\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: An emergency vehicle, A red traffic light, A broken traffic light, A car merging into a lane, A parked vehicle\n",
      " - Description: a view of a busy intersection with traffic lights and trucks\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: An emergency vehicle, A red traffic light, A car merging into a lane, A broken traffic light, A parked vehicle\n",
      " - Description: a view of a busy intersection with traffic lights and cars\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A broken traffic light, A car merging into a lane, A red traffic light\n",
      " - Description: a truck is driving down the street with traffic lights\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A construction barrier, A car merging into a lane, A broken traffic light\n",
      " - Description: a truck is driving down the street with a construction worker on the back of the truck\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A construction barrier, A car merging into a lane, A broken traffic light\n",
      " - Description: a truck driving down the street with a truck behind it\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A red traffic light, A car merging into a lane, A broken traffic light\n",
      " - Description: a truck driving down the street with a trailer attached\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00030.mp4\n",
      "Answer: B. Go straight. \n",
      "\n",
      "Justification: The frames consistently indicate that the vehicle in front is on a busy street with various traffic signals, including a red light; this suggests it would likely continue straight unless there are indications otherwise, such as a turn or obstruction.\n",
      "\n",
      "Processing 31/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00031.mp4\n",
      "Question: Is it appropriate for ego to turn right now and why? A. Yes, for a right on red. B. Yes, the traffic lights are green. C. No, there is a no right on red sign. D. No, there is cross traffic.\n",
      "Frame 1:\n",
      " - Detected Objects: A pedestrian crossing the street, A red traffic light, A broken traffic light, A pedestrian waiting at the crosswalk, A green traffic light\n",
      " - Description: a wet street at night\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A red traffic light, A broken traffic light, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A green traffic light\n",
      " - Description: a street with a red light on it\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A pedestrian crossing the street, A broken traffic light, A red traffic light, A pedestrian waiting at the crosswalk, A green traffic light\n",
      " - Description: a street with a red light at night\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A red traffic light, A pedestrian crossing the street, A broken traffic light, A pedestrian waiting at the crosswalk, A green traffic light\n",
      " - Description: a street with a red light at night\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A red traffic light, A pedestrian crossing the street, A broken traffic light, A pedestrian waiting at the crosswalk, A green traffic light\n",
      " - Description: a wet street at night\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A red traffic light, A broken traffic light, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A green traffic light\n",
      " - Description: a wet road at night\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A red traffic light, A broken traffic light, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A green traffic light\n",
      " - Description: a wet street at night\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A pedestrian crossing the street, A red traffic light, A broken traffic light, A pedestrian waiting at the crosswalk, A green traffic light\n",
      " - Description: a wet road at night\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00031.mp4\n",
      "Answer: C. No, there is a no right on red sign. \n",
      "\n",
      "The presence of a red traffic light, combined with the indication that a “no right on red” sign exists, suggests it is not appropriate for ego to turn right at this moment.\n",
      "\n",
      "Processing 32/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00032.mp4\n",
      "Question: What is the weight limit on this road? A. 3 lbs. B. 3 tons. C. 3 kgs. D. 3 oz.\n",
      "Frame 1:\n",
      " - Detected Objects: A pedestrian waiting at the crosswalk, A pedestrian crossing the street, A car merging into a lane, An emergency vehicle, A broken traffic light\n",
      " - Description: a street with cars and a crosswalk\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A pedestrian waiting at the crosswalk, A pedestrian crossing the street, A car merging into a lane, A broken traffic light, A construction barrier\n",
      " - Description: a man is crossing the street in front of a building\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A pedestrian waiting at the crosswalk, A pedestrian crossing the street, A car merging into a lane, A parked vehicle, A broken traffic light\n",
      " - Description: a white building\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A pedestrian waiting at the crosswalk, An emergency vehicle, A parked vehicle, A pedestrian crossing the street, A stop sign\n",
      " - Description: a large tree\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A pedestrian waiting at the crosswalk, A pedestrian crossing the street, An emergency vehicle, A parked vehicle, A car merging into a lane\n",
      " - Description: a large tree in the middle of the road\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A pedestrian waiting at the crosswalk, An emergency vehicle, A pedestrian crossing the street, A parked vehicle, A yield sign\n",
      " - Description: a tree in the middle of the road\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A pedestrian waiting at the crosswalk, A pedestrian crossing the street, An emergency vehicle, A construction barrier, A parked vehicle\n",
      " - Description: a street with a stop sign and a hill in the background\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A pedestrian waiting at the crosswalk, A parked vehicle, A pedestrian crossing the street, A stop sign, A yield sign\n",
      " - Description: a street with a stop sign and a pole\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00032.mp4\n",
      "Answer: The best answer is B. 3 tons. This conclusion is drawn from the context of the frames where there are vehicles, pedestrians, and construction barriers, suggesting a typical urban road that could support heavy vehicles like trucks; 3 tons is a reasonable weight limit for such a setting.\n",
      "\n",
      "Processing 33/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00033.mp4\n",
      "Question: What's wrong with ego's behavior? A. Ego is bumping into the ballard. B. Ego is speeding. C. Ego is driving on the wrong direction of the road. D. Things look normal, nothing is wrong.\n",
      "Frame 1:\n",
      " - Detected Objects: A one way signA cyclist on the road, A construction barrier, A parked vehicle, An emergency vehicle, A car merging into a lane\n",
      " - Description: a bike path at night with lights on the road\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A one way signA cyclist on the road, A construction barrier, A parked vehicle, A car merging into a lane, An emergency vehicle\n",
      " - Description: a view of a road at night with lights on\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A one way signA cyclist on the road, A construction barrier, A parked vehicle, A car merging into a lane, An emergency vehicle\n",
      " - Description: a view of a road at night with lights on\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A one way signA cyclist on the road, A construction barrier, A parked vehicle, A car merging into a lane, An emergency vehicle\n",
      " - Description: a bike lane at night with lights on the road\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A one way signA cyclist on the road, A parked vehicle, A construction barrier, A car merging into a lane, A pedestrian crossing the street\n",
      " - Description: a bike path at night with lights on the side\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A one way signA cyclist on the road, A construction barrier, A car merging into a lane, A parked vehicle, An emergency vehicle\n",
      " - Description: a bike lane at night with a lighted bike path\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A one way signA cyclist on the road, A construction barrier, A parked vehicle, A car merging into a lane, A pedestrian crossing the street\n",
      " - Description: a bike path at night with lights on\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A one way signA cyclist on the road, A parked vehicle, A construction barrier, A car merging into a lane, An emergency vehicle\n",
      " - Description: a bike path at night with lights on the road\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00033.mp4\n",
      "Answer: C. Ego is driving on the wrong direction of the road. The presence of a one-way sign indicates that driving against this direction violates traffic rules.\n",
      "\n",
      "Processing 34/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00034.mp4\n",
      "Question: How many drivable lanes in the scene that are parallel (include opposing lanes as well) to ego? A. 5. B. 4. C. 3. D. 6.\n",
      "Frame 1:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, An emergency vehicle, A construction barrier, A broken traffic light\n",
      " - Description: a street with cars driving down it and power lines\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A one way signA cyclist on the road, A pedestrian waiting at the crosswalk\n",
      " - Description: a street with cars driving down it and power lines\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A red traffic light, A pedestrian waiting at the crosswalk\n",
      " - Description: a car driving down a street with power lines in the background\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A parked vehicle, A car merging into a lane, An emergency vehicle, A pedestrian waiting at the crosswalk, A broken traffic light\n",
      " - Description: a view of a street with cars driving down it\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A construction barrier, A one way signA cyclist on the road\n",
      " - Description: a street with cars driving down it and power lines\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A red traffic light, A broken traffic light\n",
      " - Description: a street with cars driving down it\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A red traffic light, A broken traffic light\n",
      " - Description: a street with cars driving down it\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A parked vehicle, A broken traffic light, A red traffic light\n",
      " - Description: a car driving down a street with power lines and trees\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00034.mp4\n",
      "Answer: The best answer is B. 4, because the frames consistently indicate that there are at least four distinct lanes (including opposing lanes) observable in the scene with cars merging and various objects present.\n",
      "\n",
      "Processing 35/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00035.mp4\n",
      "Question: What's special about the lane to the right of ego? A. Bike lane. B. Reversible lane. C. Bus lane. D. HOV lane.\n",
      "Frame 1:\n",
      " - Detected Objects: A pedestrian crossing the street, A one way signA cyclist on the road, A broken traffic light, A red traffic light, A pedestrian waiting at the crosswalk\n",
      " - Description: a street with a few street signs and a few cars\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A one way signA cyclist on the road, A broken traffic light, A pedestrian crossing the street, A construction barrier, A red traffic light\n",
      " - Description: a street at night with a street sign and a car\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A broken traffic light, A car merging into a lane, A parked vehicle, A red traffic light, A pedestrian crossing the street\n",
      " - Description: a street at night with a car driving down it\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A car merging into a lane, A green traffic light, A pedestrian crossing the street\n",
      " - Description: a street at night with a red light\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A one way signA cyclist on the road, A car merging into a lane, A red traffic light, A broken traffic light, A pedestrian crossing the street\n",
      " - Description: a street with a red and white painted bike lane at night\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A one way signA cyclist on the road, A red traffic light, A pedestrian crossing the street, A broken traffic light, A construction barrier\n",
      " - Description: a street with a bus stop sign on it\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A construction barrier, A broken traffic light, A one way signA cyclist on the road, A car merging into a lane, A red traffic light\n",
      " - Description: a street at night with a car driving down it\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A one way signA cyclist on the road, A car merging into a lane, A pedestrian crossing the street, A broken traffic light, A parked vehicle\n",
      " - Description: a street at night with a bus and a building\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00035.mp4\n",
      "Answer: A. Bike lane.\n",
      "\n",
      "The lane to the right of ego is special because it is specifically described as having red and white painted markings indicative of a bike lane.\n",
      "\n",
      "Processing 36/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00036.mp4\n",
      "Question: Count the number of unique vehicles that enter the video frame but do not exit the video frame. A. 0. B. 1. C. 2. D. 3. E. 4.\n",
      "Frame 1:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A pedestrian waiting at the crosswalk, A yield sign, A pedestrian crossing the street\n",
      " - Description: a street with cars parked in front of a house\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A yield sign, A pedestrian waiting at the crosswalk, A pedestrian crossing the street\n",
      " - Description: a street with cars parked in front of a house\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A yield sign, A broken traffic light, A construction barrier\n",
      " - Description: a street with cars parked in front of a house\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A yield sign, A broken traffic light, A pedestrian waiting at the crosswalk\n",
      " - Description: a street view of a house at night\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A yield sign, A construction barrier, A pedestrian waiting at the crosswalk\n",
      " - Description: a street with a house and a car parked in front of it\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A pedestrian waiting at the crosswalk, A broken traffic light, A yield sign\n",
      " - Description: a street with a house and a car parked in front of it\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A yield sign, A broken traffic light, A pedestrian waiting at the crosswalk\n",
      " - Description: a street with cars parked in front of a house\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A yield sign, A broken traffic light, A pedestrian waiting at the crosswalk\n",
      " - Description: a car is driving down the street at night\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00036.mp4\n",
      "Answer: The best answer is A. 0. \n",
      "\n",
      "Justification: All vehicles detected (the parked vehicle and the emergency vehicle) are consistently present in each frame and none of them exit the frame.\n",
      "\n",
      "Processing 37/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00037.mp4\n",
      "Question: Why is ego's current lane not appropriate? A. It's for oncoming traffic. B. It's closed for roadwork. C. Heavier traffic than required. D. It's not for passenger cars.\n",
      "Frame 1:\n",
      " - Detected Objects: A car merging into a lane, A one way signA cyclist on the road, A red traffic light, A broken traffic light, A pedestrian waiting at the crosswalk\n",
      " - Description: a street with cars driving down it\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A broken traffic light, An emergency vehicle, A red traffic light, A pedestrian crossing the street, A parked vehicle\n",
      " - Description: a street with cars driving down it\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A car merging into a lane, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, An emergency vehicle, A parked vehicle\n",
      " - Description: a street with cars driving down it and a building in the background\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A car merging into a lane, A pedestrian waiting at the crosswalk, A pedestrian crossing the street, A broken traffic light, A parked vehicle\n",
      " - Description: a street with cars driving down it\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A car merging into a lane, A pedestrian waiting at the crosswalk, A broken traffic light, A pedestrian crossing the street, An emergency vehicle\n",
      " - Description: a street with cars driving down it and a building in the background\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A pedestrian waiting at the crosswalk, An emergency vehicle, A pedestrian crossing the street, A car merging into a lane, A broken traffic light\n",
      " - Description: a street with cars driving down it and a taxi cab\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A pedestrian waiting at the crosswalk, A red traffic light, A pedestrian crossing the street, A broken traffic light, A green traffic light\n",
      " - Description: a street with cars and buildings in the background\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A pedestrian waiting at the crosswalk, A pedestrian crossing the street, A car merging into a lane, A broken traffic light, A red traffic light\n",
      " - Description: a street with cars and buildings in the background\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00037.mp4\n",
      "Answer: The best answer is **A. It's for oncoming traffic.** This is justified because the presence of a red traffic light and the nature of the detected objects suggest that this lane may be designated for the opposite direction, making it inappropriate for the ego vehicle to travel in that lane.\n",
      "\n",
      "Processing 38/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00038.mp4\n",
      "Question: Count the number of unique pedestrians seen by the ego. A. 0. B. 1. C. 2. D. 3. E. 4.\n",
      "Frame 1:\n",
      " - Detected Objects: A car merging into a lane, A one way signA cyclist on the road, A parked vehicle, An emergency vehicle, A pedestrian crossing the street\n",
      " - Description: a street with cars driving down it\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, A one way signA cyclist on the road, An emergency vehicle, A pedestrian crossing the street\n",
      " - Description: a street with cars driving down it\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A car merging into a lane, A one way signA cyclist on the road, A parked vehicle, An emergency vehicle, A green traffic light\n",
      " - Description: a street with cars driving down it\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A car merging into a lane, A one way signA cyclist on the road, A parked vehicle, A pedestrian waiting at the crosswalk, A pedestrian crossing the street\n",
      " - Description: a street with cars driving down it\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, A one way signA cyclist on the road, An emergency vehicle, A pedestrian waiting at the crosswalk\n",
      " - Description: a view of cars driving down a street in san francisco\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, A one way signA cyclist on the road, An emergency vehicle, A broken traffic light\n",
      " - Description: a street with cars driving down it\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, A one way signA cyclist on the road, An emergency vehicle, A red traffic light\n",
      " - Description: a street with cars driving down it\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A parked vehicle, A car merging into a lane, An emergency vehicle, A pedestrian crossing the street, A pedestrian waiting at the crosswalk\n",
      " - Description: a street with cars and trees on both sides\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00038.mp4\n",
      "Answer: The best answer is D. 3, because there are three unique pedestrians observed: one crossing the street, one waiting at the crosswalk, and another waiting at the crosswalk in different frames.\n",
      "\n",
      "Processing 39/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00039.mp4\n",
      "Question: Why does the car in front of ego stop? A. Red Light. B. Stop Sign. C. Yielding to cross-traffic. D. Does not come to a stop.\n",
      "Frame 1:\n",
      " - Detected Objects: An emergency vehicle, A car merging into a lane, A parked vehicle, A pedestrian crossing the street, A pedestrian waiting at the crosswalk\n",
      " - Description: a car is driving down the street at night\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: An emergency vehicle, A car merging into a lane, A parked vehicle, A pedestrian crossing the street, A pedestrian waiting at the crosswalk\n",
      " - Description: a car is driving down the street at night\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A car merging into a lane, A pedestrian crossing the street, A pedestrian waiting at the crosswalk\n",
      " - Description: a car is driving down a street at night\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, A pedestrian waiting at the crosswalk, An emergency vehicle, A pedestrian crossing the street\n",
      " - Description: a car is driving down the street at night\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A parked vehicle, A car merging into a lane, An emergency vehicle, A pedestrian waiting at the crosswalk, A yield sign\n",
      " - Description: a car is parked in a parking lot at night\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A parked vehicle, A car merging into a lane, An emergency vehicle, A pedestrian waiting at the crosswalk, A pedestrian crossing the street\n",
      " - Description: a car is parked in a parking lot at night\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A parked vehicle, A car merging into a lane, An emergency vehicle, A pedestrian waiting at the crosswalk, A pedestrian crossing the street\n",
      " - Description: a car is parked in a parking lot at night\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A pedestrian waiting at the crosswalk, A car merging into a lane, A pedestrian crossing the street\n",
      " - Description: a car is parked in a parking lot at night\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00039.mp4\n",
      "Answer: C. Yielding to cross-traffic. This is the best answer as it is indicated that there are pedestrians crossing the street, suggesting the car may stop to yield to them.\n",
      "\n",
      "Processing 40/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00040.mp4\n",
      "Question: What is the white car most likely to do at the stop sign? A. turn right. B. full stop. C. proceed straight. D. turn left.\n",
      "Frame 1:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A pedestrian crossing the street, A car merging into a lane, A pedestrian waiting at the crosswalk\n",
      " - Description: a street with cars parked on both sides of the street\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A pedestrian crossing the street, A parked vehicle, A pedestrian waiting at the crosswalk, An emergency vehicle, A green traffic light\n",
      " - Description: a street with cars parked on it\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A pedestrian crossing the street, A parked vehicle, A pedestrian waiting at the crosswalk, A green traffic light, An emergency vehicle\n",
      " - Description: a street with cars driving down it and a building in the background\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A pedestrian crossing the street, A parked vehicle, A pedestrian waiting at the crosswalk, An emergency vehicle, A car merging into a lane\n",
      " - Description: a street with cars and a building in the background\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A red traffic light\n",
      " - Description: a street with cars parked on both sides\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A car merging into a lane, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A red traffic light, A green traffic light\n",
      " - Description: a street with cars parked on both sides of the road\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, An emergency vehicle\n",
      " - Description: a street with cars parked on both sides\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, An emergency vehicle, A pedestrian crossing the street, A red traffic light\n",
      " - Description: a street with cars parked on both sides of the road\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00040.mp4\n",
      "Answer: The best answer is B. full stop. \n",
      "\n",
      "Justification: The presence of a stop sign implies that the white car must come to a full stop before proceeding, as indicated by the traffic regulations at that intersection.\n",
      "\n",
      "Processing 41/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00041.mp4\n",
      "Question: Which ways may ego proceed from it's current lane? A. straight only. B. straight or left. C. left only. D. right only.\n",
      "Frame 1:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A red traffic light, A pedestrian crossing the street, A broken traffic light\n",
      " - Description: a view of a city street from a car window\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: An emergency vehicle, A red traffic light, A broken traffic light, A pedestrian crossing the street, A parked vehicle\n",
      " - Description: a street with cars driving down it and a traffic light\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A red traffic light, A broken traffic light, A parked vehicle, An emergency vehicle, A pedestrian crossing the street\n",
      " - Description: a view of a city street with cars driving down it\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A parked vehicle, A pedestrian crossing the street, An emergency vehicle, A car merging into a lane, A red traffic light\n",
      " - Description: a street with cars driving down it and traffic lights\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, An emergency vehicle, A red traffic light, A broken traffic light\n",
      " - Description: austin city council approves $1.5 million for downtown street improvements\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A car merging into a lane, A parked vehicle, A red traffic light, An emergency vehicle, A broken traffic light\n",
      " - Description: a street with cars driving down it and a traffic light\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A red traffic light, A pedestrian crossing the street, A car merging into a lane, A broken traffic light, An emergency vehicle\n",
      " - Description: a street with cars driving down it and a traffic light\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: An emergency vehicle, A car merging into a lane, A red traffic light, A broken traffic light, A parked vehicle\n",
      " - Description: a street with cars driving down it\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00041.mp4\n",
      "Answer: The best answer is **B. straight or left.** This is justified because the information indicates that there is an emergency vehicle and a red traffic light present, and while the straight path may be obstructed by the traffic light, the context suggests the potential for a left turn as the alternative option to proceed.\n",
      "\n",
      "Processing 42/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00042.mp4\n",
      "Question: Which traffic light is relevant to ego's current lane? A. The blinking left arrow. B. The green circle. C. The blinking right arrow. D. The red circle.\n",
      "Frame 1:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A red traffic light, A parked vehicle, A broken traffic light\n",
      " - Description: a car driving down a road at sunset\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A car merging into a lane, A red traffic light, A broken traffic light, An emergency vehicle, A green traffic light\n",
      " - Description: a view of a street at sunset from inside a car\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A car merging into a lane, A broken traffic light, An emergency vehicle, A red traffic light, A green traffic light\n",
      " - Description: a view of a street at sunset with cars on it\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A red traffic light, A broken traffic light, A green traffic light, An emergency vehicle, A car merging into a lane\n",
      " - Description: a view of a street at sunset with cars on it\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A red traffic light, A broken traffic light, A green traffic light, An emergency vehicle, A yield sign\n",
      " - Description: a view of a street at sunset with cars and traffic\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A red traffic light, A broken traffic light, A green traffic light, A yield sign, An emergency vehicle\n",
      " - Description: a view of a street at sunset\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A green traffic light, An emergency vehicle, A yield sign\n",
      " - Description: a view of a street at sunset\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A green traffic light, A yield sign, A stop sign\n",
      " - Description: a view of a street at sunset\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00042.mp4\n",
      "Answer: The best answer is B. The green circle.\n",
      "\n",
      "Justification: The presence of the green traffic light indicates that ego's current lane has the right of way to proceed, making it the most relevant traffic light for the driver's action.\n",
      "\n",
      "Processing 43/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00043.mp4\n",
      "Question: What type of building is the road sign indicating is ahead? A. Airport. B. Embassy. C. Restaurant. D. Hotel.\n",
      "Frame 1:\n",
      " - Detected Objects: A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A broken traffic light, An emergency vehicle, A red traffic light\n",
      " - Description: a street with a traffic light and a building in the background\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A pedestrian crossing the street, A broken traffic light, A pedestrian waiting at the crosswalk, A red traffic light, An emergency vehicle\n",
      " - Description: a street with a traffic light and a building in the background\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A pedestrian crossing the street, A green traffic light, A pedestrian waiting at the crosswalk\n",
      " - Description: a street with a traffic light and a building\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A broken traffic light, A car merging into a lane, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A red traffic light\n",
      " - Description: a view of a city street with a traffic light\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A broken traffic light, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A red traffic light, A car merging into a lane\n",
      " - Description: a street with a traffic light and a building\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A broken traffic light, A pedestrian waiting at the crosswalk, A car merging into a lane, A pedestrian crossing the street, A red traffic light\n",
      " - Description: a street with a traffic light and a building in the background\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A broken traffic light, A car merging into a lane, A red traffic light, A pedestrian crossing the street, A green traffic light\n",
      " - Description: a street with a traffic light and a building\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A car merging into a lane, A broken traffic light, A red traffic light, A green traffic light, A pedestrian crossing the street\n",
      " - Description: a street with cars driving down it and traffic lights\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00043.mp4\n",
      "Answer: Based on the information in the provided frames, my best answer to the question is D. Hotel, as the repeated focus on the street and the consistent presence of pedestrians suggests the location is a busy area typical of hotels rather than an airport, embassy, or restaurant.\n",
      "\n",
      "Processing 44/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00044.mp4\n",
      "Question: Why is it appropriate for ego to remain stopped? A. Waiting for right of way. B. For a traffic light. C. For a stop sign. D. For a pedestrian.\n",
      "Frame 1:\n",
      " - Detected Objects: A parked vehicle, A one way signA cyclist on the road, A pedestrian crossing the street, An emergency vehicle, A red traffic light\n",
      " - Description: a street with trees and cars on it\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A parked vehicle, A one way signA cyclist on the road, A red traffic light, A pedestrian crossing the street, A green traffic light\n",
      " - Description: a street with cars driving down it\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A parked vehicle, A one way signA cyclist on the road, A pedestrian crossing the street, An emergency vehicle, A pedestrian waiting at the crosswalk\n",
      " - Description: a white van is driving down a street\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A parked vehicle, A one way signA cyclist on the road, A pedestrian crossing the street, An emergency vehicle, A red traffic light\n",
      " - Description: a street with cars and trucks driving down it\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A parked vehicle, A pedestrian crossing the street, A red traffic light, A green traffic light, A one way signA cyclist on the road\n",
      " - Description: a street with cars and trees on both sides\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A parked vehicle, A red traffic light, A pedestrian crossing the street, A green traffic light, An emergency vehicle\n",
      " - Description: a street with cars and trees on both sides\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A parked vehicle, A pedestrian crossing the street, A red traffic light, A green traffic light, A one way signA cyclist on the road\n",
      " - Description: a street with cars driving down it\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A parked vehicle, A pedestrian crossing the street, A red traffic light, A green traffic light, A one way signA cyclist on the road\n",
      " - Description: a street with cars driving down it and trees on either side\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00044.mp4\n",
      "Answer: The best answer is A. Waiting for right of way. \n",
      "\n",
      "Justification: The presence of a red traffic light indicates that ego should stop and wait for the right of way, which is the legally required action before proceeding.\n",
      "\n",
      "Processing 45/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00045.mp4\n",
      "Question: Which lane is blocked by construction? A. Left most lane. B. Center lane. C. Right most lane. D. None of the above.\n",
      "Frame 1:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A construction barrier, A one way signA cyclist on the road, A parked vehicle\n",
      " - Description: a road with trees and a sign on it\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A car merging into a lane, A construction barrier, An emergency vehicle, A one way signA cyclist on the road, A yield sign\n",
      " - Description: a street with a sign on it\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A car merging into a lane, A one way signA cyclist on the road, A broken traffic light, A construction barrier, An emergency vehicle\n",
      " - Description: a street with a green sign on it\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A car merging into a lane, A one way signA cyclist on the road, An emergency vehicle, A broken traffic light, A red traffic light\n",
      " - Description: a street with a sign on it that says green road\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A car merging into a lane, A broken traffic light, A red traffic light, A pedestrian waiting at the crosswalk, An emergency vehicle\n",
      " - Description: a street with a few cars driving down it\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A car merging into a lane, A broken traffic light, A red traffic light, A one way signA cyclist on the road, A construction barrier\n",
      " - Description: a street with a few cars driving down it\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A car merging into a lane, A broken traffic light, A construction barrier, A red traffic light, A green traffic light\n",
      " - Description: a street with a car driving down it\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A construction barrier, A car merging into a lane, A broken traffic light, A red traffic light, A one way signA cyclist on the road\n",
      " - Description: a street with traffic lights and cars on it\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00045.mp4\n",
      "Answer: The best answer is A. Left most lane, because the presence of a construction barrier in multiple frames indicates that construction is affecting the left most lane.\n",
      "\n",
      "Processing 46/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00046.mp4\n",
      "Question: What is closest to the average speed of the truck in front of ego? A. 5 miles per hour. B. 17 miles per hour. C. 24 miles per hour. D. 35 miles per hour.\n",
      "Frame 1:\n",
      " - Detected Objects: An emergency vehicle, A parked vehicle, A construction barrier, A car merging into a lane, A one way signA cyclist on the road\n",
      " - Description: a truck driving down the road with a trailer attached\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A parked vehicle, A construction barrier, An emergency vehicle, A one way signA cyclist on the road, A car merging into a lane\n",
      " - Description: a truck driving down a road with a sign on it\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A construction barrier, A parked vehicle, An emergency vehicle, A car merging into a lane, A one way signA cyclist on the road\n",
      " - Description: a truck driving down a road with a fence on the side\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A construction barrier, An emergency vehicle, A parked vehicle, A car merging into a lane, A one way signA cyclist on the road\n",
      " - Description: a truck driving down the road with a trailer attached\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A construction barrier, An emergency vehicle, A parked vehicle, A car merging into a lane, A one way signA cyclist on the road\n",
      " - Description: a truck driving down a road with a large trailer attached\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A construction barrier, An emergency vehicle, A parked vehicle, A car merging into a lane, A one way signA cyclist on the road\n",
      " - Description: a truck driving down a road with a fence on the side\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A construction barrier, A parked vehicle, An emergency vehicle, A car merging into a lane, A one way signA cyclist on the road\n",
      " - Description: a truck driving down a road with a bridge in the background\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A construction barrier, A car merging into a lane, A one way signA cyclist on the road\n",
      " - Description: a truck driving down a road with a bridge in the background\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00046.mp4\n",
      "Answer: B. 17 miles per hour. The truck is consistently recorded driving down the road in multiple frames without significant acceleration or deceleration, which suggests a steady, moderate speed likely around 17 miles per hour.\n",
      "\n",
      "Processing 47/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00047.mp4\n",
      "Question: Why is ego slowing down? A. pedestrian on crosswalk. B. stop sign. C. red light. D. Open car door.\n",
      "Frame 1:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A stop sign\n",
      " - Description: a house with a car parked in front of it\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A car merging into a lane, A pedestrian waiting at the crosswalk, A stop sign\n",
      " - Description: a car is parked in front of a house\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A car merging into a lane, A stop sign, A pedestrian waiting at the crosswalk\n",
      " - Description: a car is parked in front of a house\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A car merging into a lane, A pedestrian waiting at the crosswalk, A stop sign\n",
      " - Description: a car is parked in front of a house\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A car merging into a lane, A one way signA cyclist on the road, A pedestrian waiting at the crosswalk\n",
      " - Description: a car is parked in front of a house\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A car merging into a lane, A yield sign, A stop sign\n",
      " - Description: a car is parked in front of a house\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A car merging into a lane, A pedestrian waiting at the crosswalk, A yield sign\n",
      " - Description: a car is parked in front of a house\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A parked vehicle, An emergency vehicle, A car merging into a lane, A yield sign, A one way signA cyclist on the road\n",
      " - Description: a car is parked in front of a house\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00047.mp4\n",
      "Answer: A. pedestrian on crosswalk. \n",
      "\n",
      "The consistent presence of a pedestrian waiting at the crosswalk indicates that ego is likely slowing down to yield to the pedestrian who may begin crossing the street.\n",
      "\n",
      "Processing 48/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00048.mp4\n",
      "Question: What can ego do next while the light is still red? A. Make a left turn. B. Make a right turn. C. Go in reverse. D. Stay stopped.\n",
      "Frame 1:\n",
      " - Detected Objects: A one way signA cyclist on the road, A red traffic light, A broken traffic light, A green traffic light, A pedestrian crossing the street\n",
      " - Description: a bike lane on a street at night\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A pedestrian crossing the street, A green traffic light, A pedestrian waiting at the crosswalk\n",
      " - Description: a street with a red light and a car driving on it\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A pedestrian crossing the street, A green traffic light, A pedestrian waiting at the crosswalk\n",
      " - Description: a street with a red light on it\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A green traffic light\n",
      " - Description: a street with traffic lights and a car driving by\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A green traffic light, A pedestrian crossing the street, A pedestrian waiting at the crosswalk\n",
      " - Description: a street with traffic lights and a car driving down the road\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A pedestrian waiting at the crosswalk, A green traffic light, A pedestrian crossing the street\n",
      " - Description: a street with traffic lights and a car driving down the road\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A green traffic light, A pedestrian waiting at the crosswalk, A pedestrian crossing the street\n",
      " - Description: a street with a traffic light and a car\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A green traffic light, A pedestrian crossing the street, A pedestrian waiting at the crosswalk\n",
      " - Description: a street with a traffic light and a car\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00048.mp4\n",
      "Answer: D. Stay stopped. \n",
      "\n",
      "Justification: The presence of a red traffic light indicates that vehicles are required to stop until the light changes, and thus, the safest and most lawful action for ego is to remain stopped.\n",
      "\n",
      "Processing 49/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00049.mp4\n",
      "Question: At the roundabout, which way leads to Monroe Drive? A. Straight. B. Left. C. Right.\n",
      "Frame 1:\n",
      " - Detected Objects: A broken traffic light, A car merging into a lane, A parked vehicle, A pedestrian waiting at the crosswalk, An emergency vehicle\n",
      " - Description: a car driving down a street at night\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A broken traffic light, A yield sign, A parked vehicle\n",
      " - Description: a street at night with a car driving down it\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A one way signA cyclist on the road, A construction barrier, A car merging into a lane, A yield sign, A broken traffic light\n",
      " - Description: a street at night with a car driving down it\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: An emergency vehicle, A one way signA cyclist on the road, A car merging into a lane, A parked vehicle, A pedestrian waiting at the crosswalk\n",
      " - Description: a street at night with cars driving down it\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A one way signA cyclist on the road, A pedestrian waiting at the crosswalk, A car merging into a lane, An emergency vehicle, A construction barrier\n",
      " - Description: a truck driving down a street at night\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A car merging into a lane, An emergency vehicle, A one way signA cyclist on the road, A construction barrier, A parked vehicle\n",
      " - Description: a street at night with cars driving down it\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A car merging into a lane, A one way signA cyclist on the road, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A construction barrier\n",
      " - Description: a car driving down a street at night\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: An emergency vehicle, A car merging into a lane, A parked vehicle, A one way signA cyclist on the road, A pedestrian crossing the street\n",
      " - Description: a street at night with a car driving down the road\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00049.mp4\n",
      "Answer: C. Right. The information available suggests traffic dynamics and existing signage that would direct traffic towards Monroe Drive to the right at the roundabout.\n",
      "\n",
      "Processing 50/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00050.mp4\n",
      "Question: When the light turns green, can ego traverse straight through the intersection and why? A. Yes, this is a legal maneuver. B. No, there is construction ahead. C. No, there is a sign that says yield to pedestrians. D. No, there is a sign that says all traffic must turn.\n",
      "Frame 1:\n",
      " - Detected Objects: A broken traffic light, A pedestrian waiting at the crosswalk, A pedestrian crossing the street, A red traffic light, A green traffic light\n",
      " - Description: a street with a car driving on it\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Detected Objects: A broken traffic light, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, An emergency vehicle, A red traffic light\n",
      " - Description: a car driving down a street with a traffic light\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A pedestrian waiting at the crosswalk, A pedestrian crossing the street, A green traffic light\n",
      " - Description: a street with a traffic light and a building\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Detected Objects: A broken traffic light, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A red traffic light, A green traffic light\n",
      " - Description: a street with a car driving down it\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Detected Objects: A parked vehicle, A pedestrian waiting at the crosswalk, A pedestrian crossing the street, An emergency vehicle, A broken traffic light\n",
      " - Description: a car driving down a street with a traffic light\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Detected Objects: A broken traffic light, A pedestrian crossing the street, A red traffic light, A pedestrian waiting at the crosswalk, A green traffic light\n",
      " - Description: a street with a traffic light and a building\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A green traffic light\n",
      " - Description: a street with a traffic light and a building\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Detected Objects: A broken traffic light, A red traffic light, A pedestrian crossing the street, A pedestrian waiting at the crosswalk, A green traffic light\n",
      " - Description: a street with a traffic light and a building\n",
      "\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00050.mp4\n",
      "Answer: B. No, there is construction ahead. \n",
      "\n",
      "Justification: The consistent indication of a broken traffic light, combined with the presence of pedestrians crossing, suggests that while the light might turn green, the context implies that construction or pedestrian activity would prevent safe traversal through the intersection.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import clip\n",
    "from PIL import Image\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "import openai\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "\n",
    "MY_KEY = \"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\"\n",
    "\n",
    "# OpenAI API Key (replace with your actual key)\n",
    "client = openai.OpenAI(api_key=MY_KEY)\n",
    "\n",
    "# Load BLIP-2 Processor & Model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\").to(device)\n",
    "\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Image Preprocessing Pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def extract_video_frames(video_path, num_frames=8):\n",
    "    \"\"\"\n",
    "    Extracts evenly spaced frames from a video file.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total_frames < num_frames:\n",
    "        raise ValueError(f\"Error: Video has fewer frames ({total_frames}) than requested ({num_frames})\")\n",
    "    frame_indices = torch.linspace(0, total_frames - 1, num_frames).long().tolist()\n",
    "\n",
    "    frames = []\n",
    "    for idx in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = Image.fromarray(frame)\n",
    "            frames.append(frame)  # Store PIL images instead of tensors\n",
    "    \n",
    "    cap.release()\n",
    "    return frames  # Returns a list of PIL images\n",
    "\n",
    "def detect_objects_with_clip(frame):\n",
    "    \"\"\"\n",
    "    Uses CLIP to detect objects in multiple video frames.\n",
    "    \"\"\"\n",
    "    detected_objects = []  # Store detected objects for each frame\n",
    "\n",
    "    # Define relevant road objects\n",
    "    object_classes = [\n",
    "        \"A pedestrian crossing the street\",\n",
    "        \"A red traffic light\",\n",
    "        \"A green traffic light\",\n",
    "        \"A stop sign\",\n",
    "        \"A yield sign\",\n",
    "        \"Snow\",\n",
    "        \"Mud\",\n",
    "        \"Oil\"\n",
    "        \"Railroads\",\n",
    "        \"Airport sign\",\n",
    "        \"A speed limit sign\",\n",
    "        \"A one way sign pointing right\"\n",
    "        \"A one way sign pointing left\"\n",
    "        \"A do not enter sign\"\n",
    "        \"A wrong way sign\"\n",
    "        \"A cyclist on the road\",\n",
    "        \"Traffic cone\"\n",
    "        \"A parked vehicle\",\n",
    "        \"A pedestrian waiting at the crosswalk\",\n",
    "        \"A broken traffic light\",\n",
    "    ]\n",
    "\n",
    "    # Tokenize all object classes once (to save processing time)\n",
    "    text_inputs = clip.tokenize(object_classes).to(device)\n",
    "\n",
    "    image_input = preprocess(frame).unsqueeze(0).to(device)  # Preprocess each frame\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_features = clip_model.encode_image(image_input)\n",
    "        text_features = clip_model.encode_text(text_inputs)\n",
    "\n",
    "        # Compute similarity\n",
    "        similarities = (image_features @ text_features.T).softmax(dim=-1)\n",
    "        best_matches = similarities.topk(5)  # Get top 3 detected objects for each frame\n",
    "\n",
    "    detected_objects = [object_classes[idx] for idx in best_matches.indices[0].tolist()]\n",
    "\n",
    "    return detected_objects # Returns a list of object lists\n",
    "\n",
    "\n",
    "def get_video_description(frame):\n",
    "    \"\"\"\n",
    "    Generates a textual description from extracted video frames using BLIP-2.\n",
    "    \"\"\"\n",
    "    if frame is None:\n",
    "        return None  # Skip processing if frames couldn't be extracted\n",
    "\n",
    "    inputs = processor(images=frame, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(**inputs, max_length=50)\n",
    "        video_description = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "    \n",
    "    return \" \".join(video_description)\n",
    "\n",
    "def generate_chatgpt_response(question, video_summary):\n",
    "    \"\"\"\n",
    "    Uses the video description to query ChatGPT.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"Given the information provided in each frame, give me the letter of your best answer to the following question with a one sentence justification: {question}\\n\\nVideo summary: {video_summary}\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI that answers questions based on detailed frame-by-frame video analysis with respect to a car-based ego.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=100\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "def process_inputs(video_list, question_list):\n",
    "    \"\"\"\n",
    "    Processes videos **one by one** and pairs each video with its corresponding question.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    num_videos = min(len(video_list), len(question_list))  # Prevent index errors\n",
    "\n",
    "    for i in range(num_videos):\n",
    "        video_path = video_list[i]\n",
    "        question = question_list[i]\n",
    "\n",
    "        if not os.path.exists(video_path):\n",
    "            print(f\"Skipping {video_path}: File not found\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nProcessing {i+1}/{num_videos}: {video_path}\")\n",
    "        print(f\"Question: {question}\")\n",
    "\n",
    "        frames = extract_video_frames(video_path)\n",
    "        frame_descriptions = []  # Store formatted descriptions for each frame\n",
    "\n",
    "        if not frames:\n",
    "            print(f\"Skipping {video_path}: No frames extracted\")\n",
    "            continue\n",
    "\n",
    "        for frame_idx, frame in enumerate(frames):\n",
    "            detected_objects = detect_objects_with_clip(frame)\n",
    "            video_description = get_video_description(frame)\n",
    "\n",
    "            # Format output for this frame\n",
    "            frame_info = f\"Frame {frame_idx+1}:\\n\"\n",
    "            frame_info += f\" - Detected Objects: {', '.join(detected_objects) if detected_objects else 'None'}\\n\"\n",
    "            frame_info += f\" - Description: {video_description}\\n\"\n",
    "\n",
    "            frame_descriptions.append(frame_info)\n",
    "\n",
    "        # Convert frame descriptions into a single formatted text block\n",
    "        formatted_frame_descriptions = \"\\n\".join(frame_descriptions)\n",
    "        print(formatted_frame_descriptions)\n",
    "\n",
    "        # Send to ChatGPT for reasoning\n",
    "        answer = generate_chatgpt_response(question, formatted_frame_descriptions)\n",
    "\n",
    "        results[video_path] = {\n",
    "            \"question\": question,\n",
    "            \"description\": formatted_frame_descriptions,\n",
    "            \"answer\": answer\n",
    "        }\n",
    "\n",
    "        print(f\"Completed: {video_path}\")\n",
    "        print(f\"Answer: {answer}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Load Videos\n",
    "video_directory = \"/home/ubuntu/TreeHacks2025/data/videos/videos\"\n",
    "video_files = sorted(\n",
    "    [os.path.join(video_directory, f) for f in os.listdir(video_directory) if f.endswith(\".mp4\")]\n",
    ")\n",
    "\n",
    "# Load Questions from CSV\n",
    "question_file = \"/home/ubuntu/TreeHacks2025/data/questions.csv\"\n",
    "questions = []\n",
    "\n",
    "with open(question_file, mode='r', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip header row if it exists\n",
    "    for row in reader:\n",
    "        if row:  # Ensure row is not empty\n",
    "            questions.append(row[1])  # Assuming questions are in the second column\n",
    "\n",
    "# Run sequential processing\n",
    "video_results = process_inputs(video_files, questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "341b67e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 1/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00001.mp4\n",
      "Question: Was ego doing a legal maneuver if its goal is to turn right at the intersection? A. It's legal as the lane is empty. B. It's illegal as the right turn lane is bloacked by construction. C. It's illegal as ego was cutting in other vehicles that were waiting. D. It's legal but the lane ahead is way too narrow for ego to pass.\n",
      "('00001', 'B')\n",
      "\n",
      "Processing 2/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00002.mp4\n",
      "Question: Where can ego legally park on this street? A. No parking anywhere. B. next to right curb. C. anywhere. D. next to left curb.\n",
      "('00002', 'A')\n",
      "\n",
      "Processing 3/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00003.mp4\n",
      "Question: What is the best description of the maneuver ego just did? A. Lane change to the left and then lane change to the right. B. Lane change to the right and then lane change to the left. C. Staying in a lane which curves to the left and then to the right. D. Staying in a lane which curves to the right and then to the left.\n",
      "('00003', 'C')\n",
      "\n",
      "Processing 4/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00004.mp4\n",
      "Question: Why is ego stopped? A. Judah. B. Traffic Light. C. Someone is crossing the road. D. Construction.\n",
      "('00004', 'C')\n",
      "\n",
      "Processing 5/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00005.mp4\n",
      "Question: What is the blinker state of the oncoming car, with respect to the oncoming car itself? A. LEFT. B. RIGHT. C. BOTH. D. OFF.\n",
      "('00005', 'D')\n",
      "\n",
      "Processing 6/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00006.mp4\n",
      "Question: What is the reason ego changed lanes to the left? A.  Left lane has better views. B. Current lane is exit only. C. Current lane has a lower speed limit. D. Current lane is blocked.\n",
      "('00006', 'B')\n",
      "\n",
      "Processing 7/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00007.mp4\n",
      "Question: What is the correct behavior for ego and why? A. Continue straight in a nominal scenario. B. Slow down for a pedestrian. C. Veer left to avoid an obstacle. D. Veer right to avoid an obstacle.\n",
      "('00007', 'B')\n",
      "\n",
      "Processing 8/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00008.mp4\n",
      "Question: How many flashing traffic light bulbs are there? A. 0. B. 2. C. 4. D. 6.\n",
      "('00008', 'A')\n",
      "\n",
      "Processing 9/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00009.mp4\n",
      "Question: Which one if more accurate in terms of the distance from the back of the red car in front to the front bumper of the ego? A. 20m. B. 40m. C. 60m. D. 100m.\n",
      "('00009', 'A')\n",
      "\n",
      "Processing 10/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00010.mp4\n",
      "Question: Ignoring pedestrian lights, how many traffic lights are relevant to ego? A. 2. B. 4. C. 6. D. 8.\n",
      "('00010', 'B')\n",
      "\n",
      "Processing 11/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00011.mp4\n",
      "Question: What is the status of the traffic light? A. Solid green. B. Blinking green. C. Solid red. D. Blinking red.\n",
      "('00011', 'C')\n",
      "\n",
      "Processing 12/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00012.mp4\n",
      "Question: What are the available maneuvers through the intersection for the right most lane? A. Go straight only. B. Turn right only. C. Go straight and turn right. D. None of the above.\n",
      "('00012', 'C')\n",
      "\n",
      "Processing 13/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00013.mp4\n",
      "Question: Where is the pedestrian with respect to ego? A. On the crosswalk closest to ego. B. On the crosswalk on the left. C. On the crosswalk on the right. D. On the crosswalk at the opposite side of the intersection.\n",
      "('00013', 'A')\n",
      "\n",
      "Processing 14/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00014.mp4\n",
      "Question: Why does the truck ahead of ego have its blinkers on? A. To signal a lane change away from ego. B. To signal a merge towards ego. C. To show hazardous conditions. D. Its blinkers are not on.\n",
      "('00014', 'D')\n",
      "\n",
      "Processing 15/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00015.mp4\n",
      "Question: What should ego do? A. turn right. B. pullover and yield for the emergency vehicle. C. turn left. D. come to a stop and then proceed from stop sign.\n",
      "('00015', 'B')\n",
      "\n",
      "Processing 16/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00016.mp4\n",
      "Question: What would be the most appropriate maneuver for ego from this position? A. Reverse. B. Turn left. C. Turn right. D. Go straight.\n",
      "('00016', 'B')\n",
      "\n",
      "Processing 17/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00017.mp4\n",
      "Question: What hazard is on the ground? A. Mud. B. Leaves. C. Oil. D. Snow.\n",
      "('00017', 'D')\n",
      "\n",
      "Processing 18/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00018.mp4\n",
      "Question: Why is it necessary for the car to slow down? A. For another vehicle. B. For a pedestrian. C. For an animal. D. For a traffic light.\n",
      "('00018', 'B')\n",
      "\n",
      "Processing 19/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00019.mp4\n",
      "Question: How many lanes are there in total and which lane is best for going to Half Moon Bay? A. 4 and the right most lane. B. 5 and the right most lane. C. 4 and the second right most lane. D. 5 and the second most lane.\n",
      "('00019', 'A')\n",
      "\n",
      "Processing 20/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00020.mp4\n",
      "Question: Is it safe for ego to park right here? A. yes there is a parking lot here. B. Yes the shoulder is large enough. C. No there's no safe place to pullover. D. No there's a fire station.\n",
      "('00020', 'C')\n",
      "\n",
      "Processing 21/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00021.mp4\n",
      "Question: What type of lane is to the right of ego? A. Bus lane. B. Bike lane. C. Carpool lane. D. Right-turn-only lane.\n",
      "('00021', 'B')\n",
      "\n",
      "Processing 22/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00022.mp4\n",
      "Question: At what time can ego park at the side of the road? A. 9am. B. 2pm. C. 8pm. D. None of the above.\n",
      "('00022', 'D')\n",
      "\n",
      "Processing 23/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00023.mp4\n",
      "Question: What's the state of ego-relevant traffic light? A. Green left arrow. B. Green right arrow. C. Yellow left arrow. D. Yellow right arrow.\n",
      "('00023', 'D')\n",
      "\n",
      "Processing 24/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00024.mp4\n",
      "Question: Which traffic light is the most immediately relevant for ego? A. Red light. B. Red light for right turn. C. Yellow light. D. Green light.\n",
      "('00024', 'A')\n",
      "\n",
      "Processing 25/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00025.mp4\n",
      "Question: How many vehicles appeared in the video, just consider those on the same side of ego? A. 3. B. 4. C. 5. D. 6.\n",
      "('00025', 'B')\n",
      "\n",
      "Processing 26/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00026.mp4\n",
      "Question: Which directions can ego proceed in? A. straight. B. straight or right. C. left only. D. None of the above.\n",
      "('00026', 'B')\n",
      "\n",
      "Processing 27/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00027.mp4\n",
      "Question: What's the upcoming exit number? A. 1. B. 500. C. 27. D. 80.\n",
      "('00027', 'C')\n",
      "\n",
      "Processing 28/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00028.mp4\n",
      "Question: Is there a vehicle to ego's left? A. Yes. B. No. C. Insufficient evidence. D. None of the above.\n",
      "('00028', 'C')\n",
      "\n",
      "Processing 29/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00029.mp4\n",
      "Question: Why did ego come to a stop? A. Crossing vehicle. B. No space without blocking intersection. C. Stop sign. D. Cross pedestrians.\n",
      "('00029', 'C')\n",
      "\n",
      "Processing 30/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00030.mp4\n",
      "Question: What is the most likely course of action for the vehicle in front of ego? A. Turn left. B. Go straight. C. Turn right. D. Reverse.\n",
      "('00030', 'B')\n",
      "\n",
      "Processing 31/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00031.mp4\n",
      "Question: Is it appropriate for ego to turn right now and why? A. Yes, for a right on red. B. Yes, the traffic lights are green. C. No, there is a no right on red sign. D. No, there is cross traffic.\n",
      "('00031', 'C')\n",
      "\n",
      "Processing 32/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00032.mp4\n",
      "Question: What is the weight limit on this road? A. 3 lbs. B. 3 tons. C. 3 kgs. D. 3 oz.\n",
      "('00032', 'B')\n",
      "\n",
      "Processing 33/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00033.mp4\n",
      "Question: What's wrong with ego's behavior? A. Ego is bumping into the ballard. B. Ego is speeding. C. Ego is driving on the wrong direction of the road. D. Things look normal, nothing is wrong.\n",
      "('00033', 'C')\n",
      "\n",
      "Processing 34/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00034.mp4\n",
      "Question: How many drivable lanes in the scene that are parallel (include opposing lanes as well) to ego? A. 5. B. 4. C. 3. D. 6.\n",
      "('00034', 'D')\n",
      "\n",
      "Processing 35/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00035.mp4\n",
      "Question: What's special about the lane to the right of ego? A. Bike lane. B. Reversible lane. C. Bus lane. D. HOV lane.\n",
      "('00035', 'A')\n",
      "\n",
      "Processing 36/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00036.mp4\n",
      "Question: Count the number of unique vehicles that enter the video frame but do not exit the video frame. A. 0. B. 1. C. 2. D. 3. E. 4.\n",
      "('00036', 'A')\n",
      "\n",
      "Processing 37/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00037.mp4\n",
      "Question: Why is ego's current lane not appropriate? A. It's for oncoming traffic. B. It's closed for roadwork. C. Heavier traffic than required. D. It's not for passenger cars.\n",
      "('00037', 'A')\n",
      "\n",
      "Processing 38/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00038.mp4\n",
      "Question: Count the number of unique pedestrians seen by the ego. A. 0. B. 1. C. 2. D. 3. E. 4.\n",
      "('00038', 'D')\n",
      "\n",
      "Processing 39/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00039.mp4\n",
      "Question: Why does the car in front of ego stop? A. Red Light. B. Stop Sign. C. Yielding to cross-traffic. D. Does not come to a stop.\n",
      "('00039', 'A')\n",
      "\n",
      "Processing 40/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00040.mp4\n",
      "Question: What is the white car most likely to do at the stop sign? A. turn right. B. full stop. C. proceed straight. D. turn left.\n",
      "('00040', 'B')\n",
      "\n",
      "Processing 41/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00041.mp4\n",
      "Question: Which ways may ego proceed from it's current lane? A. straight only. B. straight or left. C. left only. D. right only.\n",
      "('00041', 'B')\n",
      "\n",
      "Processing 42/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00042.mp4\n",
      "Question: Which traffic light is relevant to ego's current lane? A. The blinking left arrow. B. The green circle. C. The blinking right arrow. D. The red circle.\n",
      "('00042', 'B')\n",
      "\n",
      "Processing 43/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00043.mp4\n",
      "Question: What type of building is the road sign indicating is ahead? A. Airport. B. Embassy. C. Restaurant. D. Hotel.\n",
      "('00043', 'B')\n",
      "\n",
      "Processing 44/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00044.mp4\n",
      "Question: Why is it appropriate for ego to remain stopped? A. Waiting for right of way. B. For a traffic light. C. For a stop sign. D. For a pedestrian.\n",
      "('00044', 'A')\n",
      "\n",
      "Processing 45/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00045.mp4\n",
      "Question: Which lane is blocked by construction? A. Left most lane. B. Center lane. C. Right most lane. D. None of the above.\n",
      "('00045', 'D')\n",
      "\n",
      "Processing 46/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00046.mp4\n",
      "Question: What is closest to the average speed of the truck in front of ego? A. 5 miles per hour. B. 17 miles per hour. C. 24 miles per hour. D. 35 miles per hour.\n",
      "('00046', 'B')\n",
      "\n",
      "Processing 47/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00047.mp4\n",
      "Question: Why is ego slowing down? A. pedestrian on crosswalk. B. stop sign. C. red light. D. Open car door.\n",
      "('00047', 'A')\n",
      "\n",
      "Processing 48/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00048.mp4\n",
      "Question: What can ego do next while the light is still red? A. Make a left turn. B. Make a right turn. C. Go in reverse. D. Stay stopped.\n",
      "('00048', 'D')\n",
      "\n",
      "Processing 49/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00049.mp4\n",
      "Question: At the roundabout, which way leads to Monroe Drive? A. Straight. B. Left. C. Right.\n",
      "('00049', 'B')\n",
      "\n",
      "Processing 50/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00050.mp4\n",
      "Question: When the light turns green, can ego traverse straight through the intersection and why? A. Yes, this is a legal maneuver. B. No, there is construction ahead. C. No, there is a sign that says yield to pedestrians. D. No, there is a sign that says all traffic must turn.\n",
      "('00050', 'B')\n",
      "Results saved to output.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('00001', 'B'),\n",
       " ('00002', 'A'),\n",
       " ('00003', 'C'),\n",
       " ('00004', 'C'),\n",
       " ('00005', 'D'),\n",
       " ('00006', 'B'),\n",
       " ('00007', 'B'),\n",
       " ('00008', 'A'),\n",
       " ('00009', 'A'),\n",
       " ('00010', 'B'),\n",
       " ('00011', 'C'),\n",
       " ('00012', 'C'),\n",
       " ('00013', 'A'),\n",
       " ('00014', 'D'),\n",
       " ('00015', 'B'),\n",
       " ('00016', 'B'),\n",
       " ('00017', 'D'),\n",
       " ('00018', 'B'),\n",
       " ('00019', 'A'),\n",
       " ('00020', 'C'),\n",
       " ('00021', 'B'),\n",
       " ('00022', 'D'),\n",
       " ('00023', 'D'),\n",
       " ('00024', 'A'),\n",
       " ('00025', 'B'),\n",
       " ('00026', 'B'),\n",
       " ('00027', 'C'),\n",
       " ('00028', 'C'),\n",
       " ('00029', 'C'),\n",
       " ('00030', 'B'),\n",
       " ('00031', 'C'),\n",
       " ('00032', 'B'),\n",
       " ('00033', 'C'),\n",
       " ('00034', 'D'),\n",
       " ('00035', 'A'),\n",
       " ('00036', 'A'),\n",
       " ('00037', 'A'),\n",
       " ('00038', 'D'),\n",
       " ('00039', 'A'),\n",
       " ('00040', 'B'),\n",
       " ('00041', 'B'),\n",
       " ('00042', 'B'),\n",
       " ('00043', 'B'),\n",
       " ('00044', 'A'),\n",
       " ('00045', 'D'),\n",
       " ('00046', 'B'),\n",
       " ('00047', 'A'),\n",
       " ('00048', 'D'),\n",
       " ('00049', 'B'),\n",
       " ('00050', 'B')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import clip\n",
    "from PIL import Image\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "import openai\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "MY_KEY = \"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\"\n",
    "\n",
    "# OpenAI API Key (replace with your actual key)\n",
    "client = openai.OpenAI(api_key=MY_KEY)\n",
    "\n",
    "# Load BLIP-2 Processor & Model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\").to(device)\n",
    "\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Image Preprocessing Pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def extract_video_frames(video_path, num_frames=8):\n",
    "    \"\"\"\n",
    "    Extracts evenly spaced frames from a video file.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total_frames < num_frames:\n",
    "        raise ValueError(f\"Error: Video has fewer frames ({total_frames}) than requested ({num_frames})\")\n",
    "    frame_indices = torch.linspace(0, total_frames - 1, num_frames).long().tolist()\n",
    "\n",
    "    frames = []\n",
    "    for idx in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = Image.fromarray(frame)\n",
    "            frames.append(frame)  # Store PIL images instead of tensors\n",
    "    \n",
    "    cap.release()\n",
    "    return frames  # Returns a list of PIL images\n",
    "\n",
    "def detect_objects_with_clip(frame):\n",
    "    \"\"\"\n",
    "    Uses CLIP to detect objects in multiple video frames.\n",
    "    \"\"\"\n",
    "    detected_objects = []  # Store detected objects for each frame\n",
    "\n",
    "    # Define relevant road objects\n",
    "    object_classes = [\n",
    "        \"A pedestrian crossing the street\",\n",
    "        \"A red traffic light\",\n",
    "        \"A green traffic light\",\n",
    "        \"A stop sign\",\n",
    "        \"A yield sign\",\n",
    "        \"Snow\",\n",
    "        \"Mud\",\n",
    "        \"Oil\",\n",
    "        \"Railroads\",\n",
    "        \"Airport sign\",\n",
    "        \"A speed limit sign\",\n",
    "        \"A right one way sign\",\n",
    "        \"A left one way sign\",\n",
    "        \"A do not enter sign\",\n",
    "        \"A wrong way sign\",\n",
    "        \"A cyclist on the road\",\n",
    "        \"A bike lane\",\n",
    "        \"Traffic cone\",\n",
    "        \"A parked vehicle\",\n",
    "        \"A pedestrian waiting at the crosswalk\",\n",
    "        \"A broken traffic light\",\n",
    "    ]\n",
    "\n",
    "    # Tokenize all object classes once (to save processing time)\n",
    "    text_inputs = clip.tokenize(object_classes).to(device)\n",
    "\n",
    "    image_input = preprocess(frame).unsqueeze(0).to(device)  # Preprocess each frame\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_features = clip_model.encode_image(image_input)\n",
    "        text_features = clip_model.encode_text(text_inputs)\n",
    "\n",
    "        # Compute similarity\n",
    "        similarities = (image_features @ text_features.T).softmax(dim=-1)\n",
    "        best_matches = similarities.topk(5)  # Get top 3 detected objects for each frame\n",
    "\n",
    "    detected_objects = [object_classes[idx] for idx in best_matches.indices[0].tolist()]\n",
    "\n",
    "    return detected_objects # Returns a list of object lists\n",
    "\n",
    "\n",
    "def get_video_description(frame):\n",
    "    \"\"\"\n",
    "    Generates a textual description from extracted video frames using BLIP-2.\n",
    "    \"\"\"\n",
    "    if frame is None:\n",
    "        return None  # Skip processing if frames couldn't be extracted\n",
    "\n",
    "    inputs = processor(images=frame, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(**inputs, max_length=50)\n",
    "        video_description = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "    \n",
    "    return \" \".join(video_description)\n",
    "\n",
    "def generate_chatgpt_response(question, video_summary):\n",
    "    \"\"\"\n",
    "    Uses the video description to query ChatGPT.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"Given the information provided in each frame, give me only the letter of your best answer to the following question: {question}\\n\\nVideo summary: {video_summary}\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI that answers questions based on detailed frame-by-frame video analysis with respect to a car-based ego.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=100\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def save_results_to_csv(results, output_csv=\"/mnt/data/output.csv\"):\n",
    "    \"\"\"\n",
    "    Saves processed video results to a CSV file using Pandas.\n",
    "\n",
    "    :param results: List of tuples (video_id, answer).\n",
    "    :param output_csv: Path for the output CSV file.\n",
    "    :return: File path of the saved CSV file.\n",
    "    \"\"\"\n",
    "    # Convert results to a Pandas DataFrame\n",
    "    df = pd.DataFrame(results, columns=[\"id\", \"answer\"])\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(output_csv, index=False)  # `index=False` prevents adding an extra index column\n",
    "\n",
    "    print(f\"Results saved to {output_csv}\")\n",
    "    return output_csv  # Return the file path\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "def process_inputs(video_list, question_list):\n",
    "    \"\"\"\n",
    "    Processes videos **one by one** and pairs each video with its corresponding question.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    num_videos = min(len(video_list), len(question_list))  # Prevent index errors\n",
    "\n",
    "    for i in range(num_videos):\n",
    "        video_path = video_list[i]\n",
    "        question = question_list[i]\n",
    "\n",
    "        if not os.path.exists(video_path):\n",
    "            print(f\"Skipping {video_path}: File not found\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nProcessing {i+1}/{num_videos}: {video_path}\")\n",
    "        print(f\"Question: {question}\")\n",
    "\n",
    "        frames = extract_video_frames(video_path)\n",
    "        frame_descriptions = []  # Store formatted descriptions for each frame\n",
    "\n",
    "        if not frames:\n",
    "            print(f\"Skipping {video_path}: No frames extracted\")\n",
    "            continue\n",
    "\n",
    "        for frame_idx, frame in enumerate(frames):\n",
    "            detected_objects = detect_objects_with_clip(frame)\n",
    "            video_description = get_video_description(frame)\n",
    "\n",
    "            # Format output for this frame\n",
    "            frame_info = f\"Frame {frame_idx+1}:\\n\"\n",
    "            frame_info += f\" - Detected Objects: {', '.join(detected_objects) if detected_objects else 'None'}\\n\"\n",
    "            frame_info += f\" - Description: {video_description}\\n\"\n",
    "\n",
    "            frame_descriptions.append(frame_info)\n",
    "\n",
    "        # Convert frame descriptions into a single formatted text block\n",
    "        formatted_frame_descriptions = \"\\n\".join(frame_descriptions)\n",
    "\n",
    "        # Send to ChatGPT for reasoning\n",
    "        answer = generate_chatgpt_response(question, formatted_frame_descriptions)\n",
    "        answer = answer[0] if len(answer) >= 2 else answer\n",
    "\n",
    "        # Extract filename without directory\n",
    "        filename = os.path.basename(video_path)  # e.g., \"video_0001.mp4\"\n",
    "        \n",
    "        # Extract the numeric identifier (assumes format \"video_0001.mp4\")\n",
    "        video_id = filename.split(\"_\")[-1].split(\".\")[0]  # Extracts \"0001\"\n",
    "        \n",
    "        print((video_id, answer))\n",
    "        results.append((video_id, answer))\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Load Videos\n",
    "video_directory = \"/home/ubuntu/TreeHacks2025/data/videos/videos\"\n",
    "video_files = sorted(\n",
    "    [os.path.join(video_directory, f) for f in os.listdir(video_directory) if f.endswith(\".mp4\")]\n",
    ")\n",
    "\n",
    "# Load Questions from CSV\n",
    "question_file = \"/home/ubuntu/TreeHacks2025/data/questions.csv\"\n",
    "questions = []\n",
    "\n",
    "with open(question_file, mode='r', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip header row if it exists\n",
    "    for row in reader:\n",
    "        if row:  # Ensure row is not empty\n",
    "            questions.append(row[1])  # Assuming questions are in the second column\n",
    "\n",
    "# Run sequential processing\n",
    "video_results = process_inputs(video_files, questions)\n",
    "\n",
    "csv_file_path = save_results_to_csv(video_results)\n",
    "\n",
    "# Show the file path\n",
    "csv_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc929dd9",
   "metadata": {},
   "source": [
    "How It Works\n",
    "1. Extracts 8 frames from a 5-second video.\n",
    "2. Encodes frames using BLIP-2’s Vision Transformer (ViT).\n",
    "3. Aggregates frame embeddings (mean pooling).\n",
    "4. Sends embeddings + question to ChatGPT.\n",
    "5. ChatGPT generates an answer based on the video context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c248979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import clip\n",
    "from PIL import Image\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "import openai\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "\n",
    "class FrameAnalysis:\n",
    "    \"\"\"\n",
    "    Stores detected objects and a textual description for a single video frame.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, detected_objects, description):\n",
    "        \"\"\"\n",
    "        Initializes the FrameAnalysis object.\n",
    "\n",
    "        :param detected_objects: List of objects detected in the frame.\n",
    "        :param description: Textual description of the frame.\n",
    "        \"\"\"\n",
    "        self.detected_objects = detected_objects  # List of detected objects (CLIP)\n",
    "        self.description = description  # Frame description (BLIP-2)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Returns a string representation of the FrameAnalysis object.\n",
    "        \"\"\"\n",
    "        return f\"FrameAnalysis(Objects: {self.detected_objects}, Description: {self.description})\"\n",
    "\n",
    "MY_KEY = \"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\"\n",
    "\n",
    "# OpenAI API Key (replace with your actual key)\n",
    "client = openai.OpenAI(api_key=MY_KEY)\n",
    "\n",
    "# Load BLIP-2 Processor & Model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\").to(device)\n",
    "\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Image Preprocessing Pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def extract_video_frames(video_path, num_frames=8):\n",
    "    \"\"\"\n",
    "    Extracts evenly spaced frames from a video file.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total_frames < num_frames:\n",
    "        raise ValueError(f\"Error: Video has fewer frames ({total_frames}) than requested ({num_frames})\")\n",
    "    frame_indices = torch.linspace(0, total_frames - 1, num_frames).long().tolist()\n",
    "\n",
    "    frames = []\n",
    "    for idx in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = Image.fromarray(frame)\n",
    "            frames.append(frame)  # Store PIL images instead of tensors\n",
    "    \n",
    "    cap.release()\n",
    "    return frames  # Returns a list of PIL images\n",
    "\n",
    "def detect_objects_with_clip(frame):\n",
    "    \"\"\"\n",
    "    Uses CLIP to detect objects in multiple video frames.\n",
    "    \"\"\"\n",
    "    detected_objects = []  # Store detected objects for each frame\n",
    "\n",
    "    # Define relevant road objects\n",
    "    object_classes = [\n",
    "        \"A pedestrian crossing the street\",\n",
    "        \"A red traffic light\",\n",
    "        \"A green traffic light\",\n",
    "        \"A stop sign\",\n",
    "        \"A yield sign\",\n",
    "        \"Snow\",\n",
    "        \"Airplane sign\",\n",
    "        \"A car merging into a lane\",\n",
    "        \"A construction barrier\",\n",
    "        \"A one way sign\",\n",
    "        \"An accident scene\",\n",
    "        \"A speed limit sign\",\n",
    "        \"A cyclist on the road\",\n",
    "        \"A parked vehicle\",\n",
    "        \"A pedestrian waiting at the crosswalk\",\n",
    "        \"A broken traffic light\",\n",
    "    ]\n",
    "\n",
    "    # Tokenize all object classes once (to save processing time)\n",
    "    text_inputs = clip.tokenize(object_classes).to(device)\n",
    "\n",
    "    image_input = preprocess(frame).unsqueeze(0).to(device)  # Preprocess each frame\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_features = clip_model.encode_image(image_input)\n",
    "        text_features = clip_model.encode_text(text_inputs)\n",
    "\n",
    "        # Compute similarity\n",
    "        similarities = (image_features @ text_features.T).softmax(dim=-1)\n",
    "        best_matches = similarities.topk(3)  # Get top 3 detected objects for each frame\n",
    "\n",
    "    detected_objects = [object_classes[idx] for idx in best_matches.indices[0].tolist()]\n",
    "\n",
    "    return detected_objects # Returns a list of object lists\n",
    "\n",
    "\n",
    "def get_video_description(frame):\n",
    "    \"\"\"\n",
    "    Generates a textual description from extracted video frames using BLIP-2.\n",
    "    \"\"\"\n",
    "    if frame is None:\n",
    "        return None  # Skip processing if frames couldn't be extracted\n",
    "\n",
    "    inputs = processor(images=frame, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(**inputs, max_length=50)\n",
    "        video_description = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "    \n",
    "    return \" \".join(video_description)\n",
    "\n",
    "def generate_chatgpt_response(question, video_summary, detected_objects):\n",
    "    \"\"\"\n",
    "    Uses the video description to query ChatGPT.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    The following objects were detected in the car's driving scene using CLIP:\n",
    "    {', '.join(detected_objects)}\n",
    "\n",
    "    Additionally, BLIP-2 generated this description of the scene:\n",
    "    \"{blip_description}\"\n",
    "\n",
    "    Based on this information, describe what is happening in the scene. \n",
    "    Consider potential interactions, road risks, and the safest actions for a self-driving car.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"Given the information provided in each frame, give me the letter of your best answer to the following question with a one sentence justification: {question}\\n\\nVideo summary: {video_summary}\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI that answers questions based on detailed frame-by-frame video analysis.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=100\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "def process_inputs(video_list, question_list):\n",
    "    \"\"\"\n",
    "    Processes videos **one by one** and pairs each video with its corresponding question.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    # Ensure we only loop through the shortest list length to prevent index errors\n",
    "    num_videos = min(len(video_list), len(question_list))\n",
    "\n",
    "    for i in range(num_videos):\n",
    "        video_path = video_list[i]\n",
    "        question = question_list[i]\n",
    "        frame_discriptions = {}\n",
    "\n",
    "        if not os.path.exists(video_path):\n",
    "            print(f\"Skipping {video_path}: File not found\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nProcessing {i+1}/{num_videos}: {video_path}\")\n",
    "        print(f\"Question: {question}\")\n",
    "\n",
    "        frames = extract_video_frames(video_path)\n",
    "       \n",
    "        for frame in frames:\n",
    "            detected_objects = detect_objects_with_clip(frame)\n",
    "            video_description = get_video_description(frame)\n",
    "            print(video_description)\n",
    "            frame_data = (detected_objects, video_description)\n",
    "            print(frame_data)\n",
    "            frame_discriptions.append(frame_data)\n",
    "\n",
    "        if video_description is None:\n",
    "            print(f\"Skipping {video_path}: No frames extracted\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        answer = generate_chatgpt_response(question, frame_discriptions)\n",
    "\n",
    "        results[video_path] = {\n",
    "            \"question\": question,\n",
    "            \"description\": video_description,\n",
    "            \"answer\": answer\n",
    "        }\n",
    "\n",
    "        print(f\"Completed: {video_path}\")\n",
    "        print(f\"Answer: {answer}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Load Videos\n",
    "video_directory = \"/home/ubuntu/TreeHacks2025/data/videos/videos\"\n",
    "video_files = sorted(\n",
    "    [os.path.join(video_directory, f) for f in os.listdir(video_directory) if f.endswith(\".mp4\")]\n",
    ")\n",
    "\n",
    "# Load Questions from CSV\n",
    "question_file = \"/home/ubuntu/TreeHacks2025/data/questions.csv\"\n",
    "questions = []\n",
    "\n",
    "with open(question_file, mode='r', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip header row if it exists\n",
    "    for row in reader:\n",
    "        if row:  # Ensure row is not empty\n",
    "            questions.append(row[1])  # Assuming questions are in the second column\n",
    "\n",
    "# Run sequential processing\n",
    "video_results = process_inputs(video_files, questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735c48ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344bbb8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4df11df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n",
      "File exists: /home/ubuntu/TreeHacks2025/data/videos/videos/00001.mp4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 93\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile does not exist: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is happening in this video?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 93\u001b[0m video_summary \u001b[38;5;241m=\u001b[39m \u001b[43mget_video_description\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m answer \u001b[38;5;241m=\u001b[39m generate_chatgpt_response(question, video_summary)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mA: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 63\u001b[0m, in \u001b[0;36mget_video_description\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m     60\u001b[0m     video_embeds \u001b[38;5;241m=\u001b[39m video_embeds\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Mean pooling across frames\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Pass the visual embeddings to the text generation model (BLIP-2 Decoder) to generate text\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_embeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Generate description with a max token limit\u001b[39;00m\n\u001b[1;32m     64\u001b[0m video_description \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mdecode(generated_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m video_description\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/transformers/models/blip_2/modeling_blip_2.py:2290\u001b[0m, in \u001b[0;36mBlip2ForConditionalGeneration.generate\u001b[0;34m(self, pixel_values, input_ids, attention_mask, interpolate_pos_encoding, **generate_kwargs)\u001b[0m\n\u001b[1;32m   2287\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_accelerate()\n\u001b[1;32m   2289\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m pixel_values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 2290\u001b[0m image_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvision_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2293\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterpolate_pos_encoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolate_pos_encoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2294\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m   2295\u001b[0m image_attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(image_embeds\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mimage_embeds\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2297\u001b[0m query_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_tokens\u001b[38;5;241m.\u001b[39mexpand(image_embeds\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/transformers/models/blip_2/modeling_blip_2.py:748\u001b[0m, in \u001b[0;36mBlip2VisionModel.forward\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict, interpolate_pos_encoding)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pixel_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    746\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to specify pixel_values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 748\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolate_pos_encoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolate_pos_encoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    750\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    751\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    752\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    753\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m    754\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    755\u001b[0m )\n\u001b[1;32m    757\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/transformers/models/blip_2/modeling_blip_2.py:244\u001b[0m, in \u001b[0;36mBlip2VisionEmbeddings.forward\u001b[0;34m(self, pixel_values, interpolate_pos_encoding)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, pixel_values: torch\u001b[38;5;241m.\u001b[39mFloatTensor, interpolate_pos_encoding: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 244\u001b[0m     batch_size, _, height, width \u001b[38;5;241m=\u001b[39m pixel_values\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    245\u001b[0m     target_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_embedding\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    246\u001b[0m     patch_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_embedding(pixel_values\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtarget_dtype))  \u001b[38;5;66;03m# shape = [*, width, grid, grid]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "import openai  # For ChatGPT API calls\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# OpenAI API Key (replace with your own key)\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Load BLIP-2 Processor & Model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")  # Or use 'blip2-flan-t5-xl' for T5-based\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\").to(device)\n",
    "\n",
    "# Image Preprocessing Pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def extract_video_frames(video_path, num_frames=8):\n",
    "    \"\"\"\n",
    "    Extracts evenly spaced frames from a video file.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total_frames < num_frames:\n",
    "        raise ValueError(f\"Error: Video has fewer frames ({total_frames}) than requested ({num_frames})\")\n",
    "    frame_indices = torch.linspace(0, total_frames - 1, num_frames).long().tolist()\n",
    "\n",
    "    frames = []\n",
    "    for idx in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = Image.fromarray(frame)\n",
    "            frames.append(frame)  # Store PIL images instead of tensors\n",
    "    \n",
    "    cap.release()\n",
    "    return frames  # Returns a list of PIL images\n",
    "\n",
    "def get_video_description(video_path):\n",
    "    \"\"\"\n",
    "    Extracts a single video embedding by processing multiple frames with BLIP-2's ViT.\n",
    "    \"\"\"\n",
    "    frames = extract_video_frames(video_path)\n",
    "    inputs = processor(images=frames, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        video_embeds = model.vision_model(**inputs).last_hidden_state  # Extract ViT embeddings\n",
    "        video_embeds = video_embeds.mean(dim=1)  # Mean pooling across frames\n",
    "    \n",
    "    # Pass the visual embeddings to the text generation model (BLIP-2 Decoder) to generate text\n",
    "    generated_ids = model.generate(video_embeds, max_length=50)  # Generate description with a max token limit\n",
    "    video_description = processor.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    return video_description  # Return generated textual summary (description) of the video\n",
    "\n",
    "def generate_chatgpt_response(question, video_embeds):\n",
    "    \"\"\"\n",
    "    Uses video embeddings as context and queries ChatGPT.\n",
    "    \"\"\"\n",
    "    video_context = video_embeds.cpu().numpy().tolist()  # Convert tensor to list for API\n",
    "    prompt = f\"Answer this question based on the given video embeddings:\\n\\n{question}\"\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI that answers video-related questions.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Video embedding: {video_context}\"}\n",
    "        ],\n",
    "        max_tokens=100\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# Example Usage\n",
    "video_path = \"/home/ubuntu/TreeHacks2025/data/videos/videos/00001.mp4\"\n",
    "if os.path.exists(video_path):\n",
    "    print(f\"File exists: {video_path}\")\n",
    "else:\n",
    "    print(f\"File does not exist: {video_path}\")\n",
    "question = \"What is happening in this video?\"\n",
    "\n",
    "video_summary = get_video_description(video_path)\n",
    "answer = generate_chatgpt_response(question, video_summary)\n",
    "\n",
    "print(f\"Q: {question}\\nA: {answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49f772ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 1/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00001.mp4\n",
      "Question: Was ego doing a legal maneuver if its goal is to turn right at the intersection? A. It's legal as the lane is empty. B. It's illegal as the right turn lane is bloacked by construction. C. It's illegal as ego was cutting in other vehicles that were waiting. D. It's legal but the lane ahead is way too narrow for ego to pass.\n",
      "Video Description: a car driving down a road with construction cones and traffic cones\n",
      " a car driving down a road with construction cones and a traffic light\n",
      " a car driving down a road with construction cones\n",
      " a car driving down a street with construction cones and a traffic light\n",
      " a view of a road with traffic and construction cones\n",
      " a street with a lot of cars and cones\n",
      " a street with a lot of cars and cones\n",
      " a view of a busy street with cars and trucks\n",
      "\n",
      "Completed: /home/ubuntu/TreeHacks2025/data/videos/videos/00001.mp4\n",
      "Answer: B. It's illegal as the right turn lane is blocked by construction.\n",
      "\n",
      "Justification: The presence of construction cones indicates that the right turn lane is obstructed, making it illegal for the ego vehicle to attempt a right turn at this intersection.\n",
      "\n",
      "Processing 2/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00002.mp4\n",
      "Question: Where can ego legally park on this street? A. No parking anywhere. B. next to right curb. C. anywhere. D. next to left curb.\n",
      "Video Description: a street with a lot of traffic and buildings\n",
      " a street with a lot of traffic cones and cars\n",
      " a parking lot with a few cars parked in it\n",
      " a car parked in front of a restaurant at night\n",
      " a small car is driving down the street at night\n",
      " a car driving down a dark street at night\n",
      " a street at night with a street light\n",
      " a street at night with a street light and cones\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 141\u001b[0m\n\u001b[1;32m    138\u001b[0m             questions\u001b[38;5;241m.\u001b[39mappend(row[\u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# Assuming questions are in the second column\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# Run sequential processing\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m video_results \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestions\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[62], line 110\u001b[0m, in \u001b[0;36mprocess_inputs\u001b[0;34m(video_list, question_list)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: No frames extracted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_chatgpt_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_description\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m results[video_path] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question,\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: video_description,\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m: answer\n\u001b[1;32m    116\u001b[0m }\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[62], line 71\u001b[0m, in \u001b[0;36mgenerate_chatgpt_response\u001b[0;34m(question, video_summary)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03mUses the video description to query ChatGPT.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGiven the information provided in each frame, give me the letter of your best answer to the following question with a one sentence justification: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mVideo summary: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 71\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful AI that answers questions based on detailed frame-by-frame video analysis.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\n\u001b[1;32m     78\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:879\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    876\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    877\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    878\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/openai/_base_client.py:1290\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1278\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1285\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1286\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1287\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1288\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1289\u001b[0m     )\n\u001b[0;32m-> 1290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/openai/_base_client.py:967\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/openai/_base_client.py:1003\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1000\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1003\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1009\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/ssl.py:1292\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1290\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1291\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/ssl.py:1165\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "import openai\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "MY_KEY = \"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\"\n",
    "\n",
    "# OpenAI API Key (replace with your actual key)\n",
    "client = openai.OpenAI(api_key=MY_KEY)\n",
    "\n",
    "# Load BLIP-2 Processor & Model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\").to(device)\n",
    "\n",
    "# Image Preprocessing Pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def extract_video_frames(video_path, num_frames=8):\n",
    "    \"\"\"\n",
    "    Extracts evenly spaced frames from a video file.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total_frames < num_frames:\n",
    "        raise ValueError(f\"Error: Video has fewer frames ({total_frames}) than requested ({num_frames})\")\n",
    "    frame_indices = torch.linspace(0, total_frames - 1, num_frames).long().tolist()\n",
    "\n",
    "    frames = []\n",
    "    for idx in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = Image.fromarray(frame)\n",
    "            frames.append(frame)  # Store PIL images instead of tensors\n",
    "    \n",
    "    cap.release()\n",
    "    return frames  # Returns a list of PIL images\n",
    "\n",
    "def get_video_description(video_path):\n",
    "    \"\"\"\n",
    "    Generates a textual description from extracted video frames using BLIP-2.\n",
    "    \"\"\"\n",
    "    frames = extract_video_frames(video_path)\n",
    "    if frames is None:\n",
    "        return None  # Skip processing if frames couldn't be extracted\n",
    "\n",
    "    inputs = processor(images=frames, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(**inputs, max_length=50)\n",
    "        video_description = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "    \n",
    "    return \" \".join(video_description)\n",
    "\n",
    "def generate_chatgpt_response(question, video_summary):\n",
    "    \"\"\"\n",
    "    Uses the video description to query ChatGPT.\n",
    "    \"\"\"\n",
    "    prompt = f\"Given the information provided in each frame, give me the letter of your best answer to the following question with a one sentence justification: {question}\\n\\nVideo summary: {video_summary}\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI that answers questions based on detailed frame-by-frame video analysis.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=100\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "def process_inputs(video_list, question_list):\n",
    "    \"\"\"\n",
    "    Processes videos **one by one** and pairs each video with its corresponding question.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # Ensure we only loop through the shortest list length to prevent index errors\n",
    "    num_videos = min(len(video_list), len(question_list))\n",
    "\n",
    "    for i in range(num_videos):\n",
    "        video_path = video_list[i]\n",
    "        question = question_list[i]\n",
    "\n",
    "        if not os.path.exists(video_path):\n",
    "            print(f\"Skipping {video_path}: File not found\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nProcessing {i+1}/{num_videos}: {video_path}\")\n",
    "        print(f\"Question: {question}\")\n",
    "\n",
    "        video_description = get_video_description(video_path)\n",
    "        print(f\"Video Description: {video_description}\")\n",
    "\n",
    "        if video_description is None:\n",
    "            print(f\"Skipping {video_path}: No frames extracted\")\n",
    "            continue\n",
    "\n",
    "        answer = generate_chatgpt_response(question, video_description)\n",
    "\n",
    "        results[video_path] = {\n",
    "            \"question\": question,\n",
    "            \"description\": video_description,\n",
    "            \"answer\": answer\n",
    "        }\n",
    "\n",
    "        print(f\"Completed: {video_path}\")\n",
    "        print(f\"Answer: {answer}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Load Videos\n",
    "video_directory = \"/home/ubuntu/TreeHacks2025/data/videos/videos\"\n",
    "video_files = sorted(\n",
    "    [os.path.join(video_directory, f) for f in os.listdir(video_directory) if f.endswith(\".mp4\")]\n",
    ")\n",
    "\n",
    "# Load Questions from CSV\n",
    "question_file = \"/home/ubuntu/TreeHacks2025/data/questions.csv\"\n",
    "questions = []\n",
    "\n",
    "with open(question_file, mode='r', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip header row if it exists\n",
    "    for row in reader:\n",
    "        if row:  # Ensure row is not empty\n",
    "            questions.append(row[1])  # Assuming questions are in the second column\n",
    "\n",
    "# Run sequential processing\n",
    "video_results = process_inputs(video_files, questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "91c8baf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 1/50: /home/ubuntu/TreeHacks2025/data/videos/videos/00001.mp4\n",
      "Question: Was ego doing a legal maneuver if its goal is to turn right at the intersection? A. It's legal as the lane is empty. B. It's illegal as the right turn lane is bloacked by construction. C. It's illegal as ego was cutting in other vehicles that were waiting. D. It's legal but the lane ahead is way too narrow for ego to pass.\n",
      "['Question: What are the objects are in this image? Answer: Traffic cones\\n', 'Question: Where are cars driving? Answer:\\n']\n",
      "['Question: What are the objects are in this image? Answer: A car driving down a road\\n', 'Question: Where are cars driving? Answer:\\n']\n",
      "['Question: What are the objects are in this image? Answer: Traffic cones\\n', 'Question: Where are cars driving? Answer:\\n']\n",
      "['Question: What are the objects are in this image? Answer: Traffic cones\\n', 'Question: Where are cars driving? Answer:\\n']\n",
      "['Question: What are the objects are in this image? Answer: Traffic cones\\n', 'Question: Where are cars driving? Answer:\\n']\n",
      "['Question: What are the objects are in this image? Answer: Traffic cones\\n', 'Question: Where are cars driving? Answer:\\n']\n",
      "['Question: What are the objects are in this image? Answer: Traffic cones\\n', 'Question: Where are cars driving? Answer:\\n']\n",
      "['Question: What are the objects are in this image? Answer: A traffic jam on a highway\\n', 'Question: Where are cars driving? Answer:\\n']\n",
      "detailed description: Frame 1:\n",
      " - Question: What are the objects are in this image? Answer:: Question: What are the objects are in this image? Answer: Traffic cones\n",
      "\n",
      " - Question: Where are cars driving? Answer:: Question: Where are cars driving? Answer:\n",
      "\n",
      "\n",
      "Frame 2:\n",
      " - Question: What are the objects are in this image? Answer:: Question: What are the objects are in this image? Answer: A car driving down a road\n",
      "\n",
      " - Question: Where are cars driving? Answer:: Question: Where are cars driving? Answer:\n",
      "\n",
      "\n",
      "Frame 3:\n",
      " - Question: What are the objects are in this image? Answer:: Question: What are the objects are in this image? Answer: Traffic cones\n",
      "\n",
      " - Question: Where are cars driving? Answer:: Question: Where are cars driving? Answer:\n",
      "\n",
      "\n",
      "Frame 4:\n",
      " - Question: What are the objects are in this image? Answer:: Question: What are the objects are in this image? Answer: Traffic cones\n",
      "\n",
      " - Question: Where are cars driving? Answer:: Question: Where are cars driving? Answer:\n",
      "\n",
      "\n",
      "Frame 5:\n",
      " - Question: What are the objects are in this image? Answer:: Question: What are the objects are in this image? Answer: Traffic cones\n",
      "\n",
      " - Question: Where are cars driving? Answer:: Question: Where are cars driving? Answer:\n",
      "\n",
      "\n",
      "Frame 6:\n",
      " - Question: What are the objects are in this image? Answer:: Question: What are the objects are in this image? Answer: Traffic cones\n",
      "\n",
      " - Question: Where are cars driving? Answer:: Question: Where are cars driving? Answer:\n",
      "\n",
      "\n",
      "Frame 7:\n",
      " - Question: What are the objects are in this image? Answer:: Question: What are the objects are in this image? Answer: Traffic cones\n",
      "\n",
      " - Question: Where are cars driving? Answer:: Question: Where are cars driving? Answer:\n",
      "\n",
      "\n",
      "Frame 8:\n",
      " - Question: What are the objects are in this image? Answer:: Question: What are the objects are in this image? Answer: A traffic jam on a highway\n",
      "\n",
      " - Question: Where are cars driving? Answer:: Question: Where are cars driving? Answer:\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'you must provide a model parameter', 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 160\u001b[0m\n\u001b[1;32m    157\u001b[0m             questions\u001b[38;5;241m.\u001b[39mappend(row[\u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# Assuming questions are in the second column\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# Run sequential processing\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m video_results \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Save results (Optional)\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[83], line 128\u001b[0m, in \u001b[0;36mprocess_inputs\u001b[0;34m(video_list, question_list)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: No frames extracted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_chatgpt_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetailed_description\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m results[video_path] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question,\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetailed_description\u001b[39m\u001b[38;5;124m\"\u001b[39m: detailed_description,\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m: answer\n\u001b[1;32m    134\u001b[0m }\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[83], line 92\u001b[0m, in \u001b[0;36mgenerate_chatgpt_response\u001b[0;34m(question, detailed_description)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03mUses the detailed frame descriptions to query ChatGPT for a more specific video answer.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     90\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe video contains the following scene details from multiple frames:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdetailed_description\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAnswer the following question about the video: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 92\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful AI that answers questions based on detailed frame-by-frame video analysis.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\n\u001b[1;32m     99\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:879\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    876\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    877\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    878\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/openai/_base_client.py:1290\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1278\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1285\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1286\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1287\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1288\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1289\u001b[0m     )\n\u001b[0;32m-> 1290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/openai/_base_client.py:967\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/treehack/lib/python3.10/site-packages/openai/_base_client.py:1071\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1070\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1071\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1074\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1075\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1080\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': 'you must provide a model parameter', 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Load BLIP-2 Processor & Model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\").to(device)\n",
    "\n",
    "def extract_video_frames(video_path, num_frames=8):\n",
    "    \"\"\"\n",
    "    Extracts evenly spaced frames from a video file.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total_frames < num_frames:\n",
    "        print(f\"Skipping {video_path}: Not enough frames ({total_frames})\")\n",
    "        return None\n",
    "\n",
    "    frame_indices = torch.linspace(0, total_frames - 1, num_frames).long().tolist()\n",
    "    frames = []\n",
    "\n",
    "    for idx in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = Image.fromarray(frame)\n",
    "            frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    return frames if frames else None  # Returns a list of PIL images\n",
    "\n",
    "def get_detailed_video_description(video_path):\n",
    "    \"\"\"\n",
    "    Generates detailed descriptions for each frame by querying BLIP-2 in batch.\n",
    "    \"\"\"\n",
    "    frames = extract_video_frames(video_path)\n",
    "    if frames is None:\n",
    "        return None\n",
    "\n",
    "    frame_descriptions = []\n",
    "    \n",
    "    prompts = [\n",
    "        \"Question: What are the objects are in this image? Answer:\",\n",
    "        \"Question: Where are cars driving? Answer:\"\n",
    "       # \"Question: What are the shape of the signs? Answer:\",\n",
    "    ]\n",
    "\n",
    "    for i, frame in enumerate(frames):\n",
    "        # Create batch queries\n",
    "        inputs = processor(\n",
    "            images=[frame] * len(prompts),\n",
    "            text=prompts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True  # Ensure correct token alignment\n",
    "        ).to(device)\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(\n",
    "                **inputs,\n",
    "                temperature=1.0,\n",
    "                repetition_penalty=1.2\n",
    "            )\n",
    "\n",
    "        # Decode all responses at once\n",
    "        descriptions = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        print(descriptions)\n",
    "\n",
    "        # Format output for this frame\n",
    "        frame_info = f\"Frame {i+1}:\\n\"\n",
    "        for prompt, description in zip(prompts, descriptions):\n",
    "            if description.strip() == \"\":\n",
    "                description = \"No meaningful response generated\"  # Handle empty outputs\n",
    "            frame_info += f\" - {prompt}: {description}\\n\"\n",
    "\n",
    "        frame_descriptions.append(frame_info)\n",
    "\n",
    "    return \"\\n\".join(frame_descriptions)  # Concatenate all frame details\n",
    "\n",
    "\n",
    "def generate_chatgpt_response(question, detailed_description):\n",
    "    \"\"\"\n",
    "    Uses the detailed frame descriptions to query ChatGPT for a more specific video answer.\n",
    "    \"\"\"\n",
    "    prompt = f\"The video contains the following scene details from multiple frames:\\n{detailed_description}\\n\\nAnswer the following question about the video: {question}\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI that answers questions based on detailed frame-by-frame video analysis.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=100\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def process_inputs(video_list, question_list):\n",
    "    \"\"\"\n",
    "    Processes videos one by one with improved frame-specific descriptions.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    num_videos = min(len(video_list), len(question_list))\n",
    "\n",
    "    for i in range(num_videos):\n",
    "        video_path = video_list[i]\n",
    "        question = question_list[i]\n",
    "\n",
    "        if not os.path.exists(video_path):\n",
    "            print(f\"Skipping {video_path}: File not found\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nProcessing {i+1}/{num_videos}: {video_path}\")\n",
    "        print(f\"Question: {question}\")\n",
    "\n",
    "        detailed_description = get_detailed_video_description(video_path)\n",
    "        print(f\"detailed description: {detailed_description}\")\n",
    "\n",
    "        if detailed_description is None:\n",
    "            print(f\"Skipping {video_path}: No frames extracted\")\n",
    "            continue\n",
    "\n",
    "        answer = generate_chatgpt_response(question, detailed_description)\n",
    "\n",
    "        results[video_path] = {\n",
    "            \"question\": question,\n",
    "            \"detailed_description\": detailed_description,\n",
    "            \"answer\": answer\n",
    "        }\n",
    "\n",
    "        print(f\"Completed: {video_path}\")\n",
    "        print(f\"Video Details:\\n{detailed_description}\")\n",
    "        print(f\"Answer: {answer}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Load Videos\n",
    "video_directory = \"/home/ubuntu/TreeHacks2025/data/videos/videos\"\n",
    "video_files = sorted(\n",
    "    [os.path.join(video_directory, f) for f in os.listdir(video_directory) if f.endswith(\".mp4\")]\n",
    ")\n",
    "\n",
    "# Load Questions from CSV\n",
    "question_file = \"/home/ubuntu/TreeHacks2025/data/questions.csv\"\n",
    "questions = []\n",
    "\n",
    "with open(question_file, mode='r', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip header row if it exists\n",
    "    for row in reader:\n",
    "        if row:  # Ensure row is not empty\n",
    "            questions.append(row[1])  # Assuming questions are in the second column\n",
    "\n",
    "# Run sequential processing\n",
    "video_results = process_inputs(video_files, questions)\n",
    "\n",
    "# Save results (Optional)\n",
    "import json\n",
    "with open(\"video_results.json\", \"w\") as f:\n",
    "    json.dump(video_results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ebc07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/home/ubuntu/TreeHacks2025/data/videos/videos/00002.mp4\"\n",
    "\n",
    "if os.path.exists(video_path):\n",
    "    print(f\"File exists: {video_path}\")\n",
    "    question = \"Where can ego legally park on this street? A. No parking anywhere. B. next to right curb. C. anywhere. D. next to left curb.\"\n",
    "    \n",
    "    # Get video description\n",
    "    video_summary = get_video_description(video_path)\n",
    "    print(f\"Video Summary: {video_summary}\")\n",
    "\n",
    "    # Generate answer using ChatGPT\n",
    "    answer = generate_chatgpt_response(question, video_summary)\n",
    "    \n",
    "    print(f\"Q: {question}\\nA: {answer}\")\n",
    "else:\n",
    "    print(f\"File does not exist: {video_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25d16fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: /home/ubuntu/TreeHacks2025/data/videos/videos/00001.mp4\n",
      "Detected Objects: {'What objects are in the image?\\n': 8}\n",
      "Video Description:\n",
      "I'm afraid the information you've provided is a bit unclear. It mentions \"8 What objects are in the image?\" but doesn't specify what those objects are. If you can provide a list of the objects detected in the video, I can help you with a description of the scene and what's happening.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "from openai import OpenAI\n",
    "import cv2\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "MY_KEY = \"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\"\n",
    "\n",
    "# OpenAI API Key (replace with your actual key)\n",
    "client = openai.OpenAI(api_key=MY_KEY)\n",
    "\n",
    "# Load BLIP-2 Processor & Model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\").to(device)\n",
    "\n",
    "# Image Preprocessing Pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def extract_video_frames(video_path, num_frames=8):\n",
    "    \"\"\"\n",
    "    Extracts evenly spaced frames from a video file.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total_frames < num_frames:\n",
    "        raise ValueError(f\"Error: Video has fewer frames ({total_frames}) than requested ({num_frames})\")\n",
    "    frame_indices = torch.linspace(0, total_frames - 1, num_frames).long().tolist()\n",
    "\n",
    "    frames = []\n",
    "    for idx in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = Image.fromarray(frame)\n",
    "            frames.append(frame)  # Store PIL images instead of tensors\n",
    "    \n",
    "    cap.release()\n",
    "    return frames  # Returns a list of PIL images\n",
    "\n",
    "def get_detected_objects(video_path):\n",
    "    \"\"\"\n",
    "    Uses BLIP-2 to generate a list of detected objects from video frames.\n",
    "    \"\"\"\n",
    "    frames = extract_video_frames(video_path)\n",
    "    \n",
    "    detected_objects = Counter()\n",
    "    \n",
    "    for frame in frames:\n",
    "        inputs = processor(images=frame, text=\"What objects are in the image?\", return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(**inputs, max_length=50)\n",
    "            description = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        \n",
    "        # Extract object names and count occurrences\n",
    "        for obj in description.split(\", \"):\n",
    "            detected_objects[obj] += 1\n",
    "    \n",
    "    return detected_objects\n",
    "\n",
    "def generate_chatgpt_response(detected_objects):\n",
    "    \"\"\"\n",
    "    Uses detected objects as context and queries ChatGPT-4o for a video description.\n",
    "    \"\"\"\n",
    "    object_summary = \", \".join([f\"{count} {obj}\" for obj, count in detected_objects.items()])\n",
    "    prompt = f\"The video contains the following objects: {object_summary}. Describe what is happening in the video.\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI that describes video scenes based on detected objects.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=100\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example Usage\n",
    "video_path = \"/home/ubuntu/TreeHacks2025/data/videos/videos/00002.mp4\"\n",
    "\n",
    "if os.path.exists(video_path):\n",
    "    print(f\"File exists: {video_path}\")\n",
    "    \n",
    "    # Detect objects in video frames\n",
    "    detected_objects = get_detected_objects(video_path)\n",
    "    print(f\"Detected Objects: {dict(detected_objects)}\")\n",
    "\n",
    "    # Generate answer using ChatGPT\n",
    "    video_description = generate_chatgpt_response(detected_objects)\n",
    "    \n",
    "    print(f\"Video Description:\\n{video_description}\")\n",
    "else:\n",
    "    print(f\"File does not exist: {video_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504c625f",
   "metadata": {},
   "source": [
    "2. Fine-Tuning BLIP-2 for Video Question Answering\n",
    "Objective: Teach BLIP-2 to process ego-centric video frames and answer driving-related questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df1ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"video_id\": \"example_video.mp4\",\n",
    "  \"frames\": [\"frame_1.jpg\", \"frame_2.jpg\", ..., \"frame_8.jpg\"],  \n",
    "  \"question\": \"Is the car allowed to turn right at this intersection?\",  \n",
    "  \"answer\": \"No, because there is a no-right-turn sign.\"  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e318349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration, TrainingArguments, Trainer\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Load BLIP-2 Model & Processor\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"Salesforce/blip2-opt-2.7b\"\n",
    "processor = Blip2Processor.from_pretrained(model_name)\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Load Your Dataset\n",
    "class DrivingVideoQADataset(Dataset):\n",
    "    def __init__(self, json_file, processor):\n",
    "        with open(json_file, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        frames = [Image.open(frame_path).convert(\"RGB\") for frame_path in sample[\"frames\"]]\n",
    "        inputs = self.processor(images=frames, text=sample[\"question\"], return_tensors=\"pt\", padding=True)\n",
    "        inputs[\"labels\"] = self.processor.tokenizer(sample[\"answer\"], return_tensors=\"pt\")[\"input_ids\"]\n",
    "        return {k: v.squeeze(0) for k, v in inputs.items()}  # Remove batch dim\n",
    "\n",
    "# Initialize Dataset & DataLoader\n",
    "dataset = DrivingVideoQADataset(\"driving_video_qa.json\", processor)\n",
    "\n",
    "# Training Configuration\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./blip2_driving\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=5,\n",
    "    logging_dir=\"./logs\",\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=dataset,\n",
    ")\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
